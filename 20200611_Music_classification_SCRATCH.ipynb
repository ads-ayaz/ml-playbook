{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20200611 - Music classification - SCRATCH.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4kOd3oi7r9Ru"
      ],
      "toc_visible": true,
      "mount_file_id": "1u-XAi8WvCRYjhCJoeowDaBtSt5F5Z0gb",
      "authorship_tag": "ABX9TyN7jTW/RBK6mdP6lJs3yHZN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ads-ayaz/ml-playbook/blob/master/20200611_Music_classification_SCRATCH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l_ezAy95344",
        "colab_type": "text"
      },
      "source": [
        "<h1><strong>Machine Learning Playbook</strong> | Aluance Digital</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4SR6h0Y6I8_",
        "colab_type": "text"
      },
      "source": [
        "Machine learning projects have a lot of steps and stages to them. Executing a successful project can be made a whole lot easier when you have a framework that organizes the whole approach.\n",
        "\n",
        "That's why Aluance developed this \"playbook\" it simultaneously acts as a machine learning project template and a collection of best practices. The playbook is continually updated, and can be forked whenever a new project is initiated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwFkRgls7EbU",
        "colab_type": "text"
      },
      "source": [
        "# How to use this playbook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Ibn9ph7_Fl",
        "colab_type": "text"
      },
      "source": [
        "# Problem statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wou09bV48IYk",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkEyngU_ZiuC",
        "colab_type": "text"
      },
      "source": [
        "Install or upgrade missing libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPDtVLDDZc9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "65b6e93f-a083-4dd6-fbe7-71faf62f9730"
      },
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "\n",
        "# For the current version: \n",
        "#!pip install --upgrade tensorflow\n",
        "\n",
        "!pip show Keras\n",
        "#!pip install --upgrade Keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.2.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: opt-einsum, h5py, termcolor, numpy, google-pasta, absl-py, keras-preprocessing, gast, protobuf, tensorboard, wheel, scipy, six, tensorflow-estimator, wrapt, grpcio, astunparse\n",
            "Required-by: fancyimpute\n",
            "Name: Keras\n",
            "Version: 2.3.1\n",
            "Summary: Deep Learning for humans\n",
            "Home-page: https://github.com/keras-team/keras\n",
            "Author: Francois Chollet\n",
            "Author-email: francois.chollet@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: numpy, pyyaml, h5py, keras-applications, keras-preprocessing, six, scipy\n",
            "Required-by: textgenrnn, keras-vis, kapre, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Myk6w3Znte",
        "colab_type": "text"
      },
      "source": [
        "Import the libraries needed for this project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzdZfAIv7QSv",
        "colab_type": "code",
        "outputId": "b83f340b-5676-4a4f-c68e-62aa14ff3daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.layers import Dense             # Dense describes how the layers are connected\n",
        "from keras.models import Sequential        # Sequential means we are creating a sequence of connectec layers\n",
        "from keras.optimizers import SGD           # Sochastic gradient descent is the method used to find local minimum\n",
        "#from tensorflow.keras.optimizers.schedules import ExponentialDecay    # Used for schedules.ExponentialDecay\n",
        "\n",
        "import matplotlib.pyplot as plt            # visualize images\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIAIjJg38N8s",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O43PMxT62RV",
        "colab_type": "text"
      },
      "source": [
        "## Acquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx8ojHS4qx_o",
        "colab_type": "text"
      },
      "source": [
        "After uploading the source data file, use the following commands to unzip the contents into the `data` folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9UFqed6qFo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment the lines below to execute.\n",
        "#!unzip /content/drive/My\\ Drive/_ml/_datasets/GTZAN\\ dataset\\ -\\ 568973_1032238_bundle_archive.zip -d /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kOd3oi7r9Ru",
        "colab_type": "text"
      },
      "source": [
        "## Unpacking the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpWO_bV-sL1E",
        "colab_type": "text"
      },
      "source": [
        "The GTZAN data set includes a folder called `genres_original` that categorizes 30 second music samples in folders labeled by genre. Each sample is a `.wav` file, whose filename follows the format `<genre_label>.<num_id>.wav`. The collection comprises 10 genres folders each containing 100 audio files.\n",
        "\n",
        "The `images_original` folder contains a Mel Spectogram image in `.png` format for each music sample. Each spectogram provides a visual representation for one of the audio files. The files are organized into folders by genre and the file naming convention is `<genre_label><num_id>.png`, where the num_ids match those of the corresponding  music sample audio files.\n",
        "\n",
        "The data set also comes with two `.csv` files that list features for the music samples in either their full 30 second format (`features_30_sec.csv`) or in 3 second segments (`features_3_sec.csv`). Breaking the samples up effectively tripples the available data samples to 3,000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6qrmUrjxnTW",
        "colab_type": "text"
      },
      "source": [
        "Here are the fields that each of the `.csv` files contain:\n",
        "\n",
        "| Field | Format | Description | Notes |\n",
        "| --- | --- | --- | --- |\n",
        "| filename | string | Name of the music sample `.wav` file.|Segments in the `3_sec` file denoted<br/> as `<fname>.<segment>.wav`. |\n",
        "| length | int | Size of the file in bytes | [CHECK] |\n",
        "| chroma_stft_mean<br/>chroma_stft_var | float | The mean and variance of the _chroma_ of the audio sample. | See: [Wikipedia](https://en.wikipedia.org/wiki/Chroma_feature)|\n",
        "| rms_mean<br/>rms_var | float |||\n",
        "| spectral_centroid_mean<br/>spectral_centroid_var | float |||\n",
        "| spectral_bandwidth_mean<br/>spectral_bandwidth_var | float |||\n",
        "| rolloff_mean<br/>rolloff_var | float |||\n",
        "| zero_crossing_rate_mean<br/>zero_crossing_rate_var | float |||\n",
        "| harmony_mean<br/>harmony_var | float |||\n",
        "| perceptr_mean<br/>perceptr_var | float |||\n",
        "| tempo | float | The _tempo_ or speed of the beat in BPM. ||\n",
        "| mfcc00_var<br/>mfcc00_mean | float | Mean and variance of **mel-frequency cepstral coefficients**. | See: [Wikipedia](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum) |\n",
        "| label | string | Musical genre of the sample. ||\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dzbdKhO8Es3",
        "colab_type": "text"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNsPSRIv8OgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FOLDER_pwd = os.getcwd()\n",
        "FOLDER_data_root = \"data/\"\n",
        "FOLDER_csv = FOLDER_data_root + \"Data/\"\n",
        "\n",
        "FILE_features30 = \"features_30_sec.csv\"\n",
        "FILE_features3 = \"features_3_sec.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxTUzxiD_wVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import using NumPy\n",
        "# raw_data = np.genfromtxt(FOLDER_csv + FILE_features30, delimiter=',')\n",
        "# raw_data = raw_data[1:, 2:]\n",
        "# np.shape(raw_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFi6x4SK_0FP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import using Pandas\n",
        "df_raw = pd.read_csv(FOLDER_csv + FILE_features30)\n",
        "\n",
        "# Create X as matrix of [n_features, m_examples], dropping some cols\n",
        "df_X_raw = df_raw.drop(['filename', 'length', 'label'], axis=1)\n",
        "\n",
        "# Create Y as matrix of [1, m] labels\n",
        "df_Y_raw = pd.DataFrame(df_raw['label'])\n",
        "#Y_raw = np.reshape(np.array(df_raw['label']), (np.shape(X_raw)[0], 1))\n",
        "\n",
        "# Shuffle X, Y\n",
        "df_X, df_Y = shuffle(df_X_raw, df_Y_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Jl2xv7IEHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "50274206-cbac-4e87-bf7c-16721a92d14d"
      },
      "source": [
        "df_X"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>rms_mean</th>\n",
              "      <th>rms_var</th>\n",
              "      <th>spectral_centroid_mean</th>\n",
              "      <th>spectral_centroid_var</th>\n",
              "      <th>spectral_bandwidth_mean</th>\n",
              "      <th>spectral_bandwidth_var</th>\n",
              "      <th>rolloff_mean</th>\n",
              "      <th>rolloff_var</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_var</th>\n",
              "      <th>harmony_mean</th>\n",
              "      <th>harmony_var</th>\n",
              "      <th>perceptr_mean</th>\n",
              "      <th>perceptr_var</th>\n",
              "      <th>tempo</th>\n",
              "      <th>mfcc1_mean</th>\n",
              "      <th>mfcc1_var</th>\n",
              "      <th>mfcc2_mean</th>\n",
              "      <th>mfcc2_var</th>\n",
              "      <th>mfcc3_mean</th>\n",
              "      <th>mfcc3_var</th>\n",
              "      <th>mfcc4_mean</th>\n",
              "      <th>mfcc4_var</th>\n",
              "      <th>mfcc5_mean</th>\n",
              "      <th>mfcc5_var</th>\n",
              "      <th>mfcc6_mean</th>\n",
              "      <th>mfcc6_var</th>\n",
              "      <th>mfcc7_mean</th>\n",
              "      <th>mfcc7_var</th>\n",
              "      <th>mfcc8_mean</th>\n",
              "      <th>mfcc8_var</th>\n",
              "      <th>mfcc9_mean</th>\n",
              "      <th>mfcc9_var</th>\n",
              "      <th>mfcc10_mean</th>\n",
              "      <th>mfcc10_var</th>\n",
              "      <th>mfcc11_mean</th>\n",
              "      <th>mfcc11_var</th>\n",
              "      <th>mfcc12_mean</th>\n",
              "      <th>mfcc12_var</th>\n",
              "      <th>mfcc13_mean</th>\n",
              "      <th>mfcc13_var</th>\n",
              "      <th>mfcc14_mean</th>\n",
              "      <th>mfcc14_var</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "      <th>mfcc20_mean</th>\n",
              "      <th>mfcc20_var</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>0.393456</td>\n",
              "      <td>0.095185</td>\n",
              "      <td>0.210817</td>\n",
              "      <td>0.007254</td>\n",
              "      <td>3758.647453</td>\n",
              "      <td>1.460349e+06</td>\n",
              "      <td>3293.503937</td>\n",
              "      <td>179924.365617</td>\n",
              "      <td>7853.715412</td>\n",
              "      <td>3.225277e+06</td>\n",
              "      <td>0.177561</td>\n",
              "      <td>0.010057</td>\n",
              "      <td>1.407944e-06</td>\n",
              "      <td>0.015856</td>\n",
              "      <td>-0.000101</td>\n",
              "      <td>0.021228</td>\n",
              "      <td>103.359375</td>\n",
              "      <td>-44.237698</td>\n",
              "      <td>4667.605957</td>\n",
              "      <td>51.353153</td>\n",
              "      <td>982.319885</td>\n",
              "      <td>24.982996</td>\n",
              "      <td>728.473206</td>\n",
              "      <td>12.159593</td>\n",
              "      <td>385.409973</td>\n",
              "      <td>10.874250</td>\n",
              "      <td>177.306381</td>\n",
              "      <td>7.613763</td>\n",
              "      <td>198.092514</td>\n",
              "      <td>8.213783</td>\n",
              "      <td>132.994537</td>\n",
              "      <td>-0.759989</td>\n",
              "      <td>103.267181</td>\n",
              "      <td>5.952502</td>\n",
              "      <td>122.356804</td>\n",
              "      <td>4.756770</td>\n",
              "      <td>90.301605</td>\n",
              "      <td>-2.507542</td>\n",
              "      <td>70.644058</td>\n",
              "      <td>1.324472</td>\n",
              "      <td>71.292839</td>\n",
              "      <td>-1.957549</td>\n",
              "      <td>69.426262</td>\n",
              "      <td>-0.456011</td>\n",
              "      <td>58.115292</td>\n",
              "      <td>0.236963</td>\n",
              "      <td>57.809673</td>\n",
              "      <td>-2.001880</td>\n",
              "      <td>64.561363</td>\n",
              "      <td>-1.966624</td>\n",
              "      <td>68.404198</td>\n",
              "      <td>-1.035476</td>\n",
              "      <td>68.450081</td>\n",
              "      <td>0.521438</td>\n",
              "      <td>56.259830</td>\n",
              "      <td>-0.377610</td>\n",
              "      <td>92.051102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>0.403845</td>\n",
              "      <td>0.099548</td>\n",
              "      <td>0.247032</td>\n",
              "      <td>0.008198</td>\n",
              "      <td>3184.921787</td>\n",
              "      <td>1.336675e+06</td>\n",
              "      <td>3285.422460</td>\n",
              "      <td>115986.367896</td>\n",
              "      <td>7471.147166</td>\n",
              "      <td>2.272039e+06</td>\n",
              "      <td>0.107511</td>\n",
              "      <td>0.009958</td>\n",
              "      <td>-6.574594e-07</td>\n",
              "      <td>0.039275</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>0.013127</td>\n",
              "      <td>95.703125</td>\n",
              "      <td>-78.819771</td>\n",
              "      <td>3218.545898</td>\n",
              "      <td>51.530029</td>\n",
              "      <td>1040.440918</td>\n",
              "      <td>42.267738</td>\n",
              "      <td>299.545380</td>\n",
              "      <td>30.088554</td>\n",
              "      <td>241.155640</td>\n",
              "      <td>20.084763</td>\n",
              "      <td>225.848083</td>\n",
              "      <td>6.969689</td>\n",
              "      <td>109.306068</td>\n",
              "      <td>8.027858</td>\n",
              "      <td>115.698692</td>\n",
              "      <td>6.881748</td>\n",
              "      <td>121.014885</td>\n",
              "      <td>-4.623488</td>\n",
              "      <td>112.174187</td>\n",
              "      <td>3.663356</td>\n",
              "      <td>98.125450</td>\n",
              "      <td>3.634636</td>\n",
              "      <td>90.500443</td>\n",
              "      <td>4.333865</td>\n",
              "      <td>70.354431</td>\n",
              "      <td>2.605772</td>\n",
              "      <td>72.926140</td>\n",
              "      <td>0.761683</td>\n",
              "      <td>69.050369</td>\n",
              "      <td>-9.158778</td>\n",
              "      <td>68.649925</td>\n",
              "      <td>-2.163452</td>\n",
              "      <td>50.640205</td>\n",
              "      <td>-2.679224</td>\n",
              "      <td>54.457802</td>\n",
              "      <td>-5.529989</td>\n",
              "      <td>33.797115</td>\n",
              "      <td>-1.328599</td>\n",
              "      <td>32.061016</td>\n",
              "      <td>-2.477071</td>\n",
              "      <td>34.385494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>0.488327</td>\n",
              "      <td>0.072437</td>\n",
              "      <td>0.175750</td>\n",
              "      <td>0.002050</td>\n",
              "      <td>3303.162310</td>\n",
              "      <td>4.613148e+05</td>\n",
              "      <td>2913.586172</td>\n",
              "      <td>77322.772148</td>\n",
              "      <td>6717.201945</td>\n",
              "      <td>1.251586e+06</td>\n",
              "      <td>0.177533</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>1.434830e-04</td>\n",
              "      <td>0.013740</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>0.007593</td>\n",
              "      <td>135.999178</td>\n",
              "      <td>-7.846319</td>\n",
              "      <td>1578.752930</td>\n",
              "      <td>59.529739</td>\n",
              "      <td>340.882874</td>\n",
              "      <td>3.647023</td>\n",
              "      <td>230.159729</td>\n",
              "      <td>28.992725</td>\n",
              "      <td>97.259422</td>\n",
              "      <td>4.147532</td>\n",
              "      <td>70.677315</td>\n",
              "      <td>10.272942</td>\n",
              "      <td>44.824116</td>\n",
              "      <td>2.554184</td>\n",
              "      <td>75.550003</td>\n",
              "      <td>7.595525</td>\n",
              "      <td>38.706879</td>\n",
              "      <td>-1.404189</td>\n",
              "      <td>39.589066</td>\n",
              "      <td>2.967205</td>\n",
              "      <td>43.797783</td>\n",
              "      <td>4.057471</td>\n",
              "      <td>36.889427</td>\n",
              "      <td>-0.747674</td>\n",
              "      <td>31.860336</td>\n",
              "      <td>1.066255</td>\n",
              "      <td>28.230644</td>\n",
              "      <td>-3.047848</td>\n",
              "      <td>24.549204</td>\n",
              "      <td>-1.013652</td>\n",
              "      <td>43.443981</td>\n",
              "      <td>-0.693758</td>\n",
              "      <td>29.216442</td>\n",
              "      <td>-0.681638</td>\n",
              "      <td>26.359278</td>\n",
              "      <td>1.524251</td>\n",
              "      <td>24.035576</td>\n",
              "      <td>-0.455842</td>\n",
              "      <td>26.617897</td>\n",
              "      <td>0.505033</td>\n",
              "      <td>25.160053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>968</th>\n",
              "      <td>0.401931</td>\n",
              "      <td>0.082724</td>\n",
              "      <td>0.091213</td>\n",
              "      <td>0.000554</td>\n",
              "      <td>2467.284654</td>\n",
              "      <td>2.824928e+05</td>\n",
              "      <td>2399.022704</td>\n",
              "      <td>44680.822416</td>\n",
              "      <td>5402.860524</td>\n",
              "      <td>7.896660e+05</td>\n",
              "      <td>0.118275</td>\n",
              "      <td>0.002549</td>\n",
              "      <td>-1.510896e-03</td>\n",
              "      <td>0.004620</td>\n",
              "      <td>-0.002149</td>\n",
              "      <td>0.001898</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-121.094696</td>\n",
              "      <td>1688.805664</td>\n",
              "      <td>91.731079</td>\n",
              "      <td>414.800598</td>\n",
              "      <td>-14.718758</td>\n",
              "      <td>243.078278</td>\n",
              "      <td>52.959843</td>\n",
              "      <td>83.926407</td>\n",
              "      <td>-11.411079</td>\n",
              "      <td>73.589119</td>\n",
              "      <td>31.013081</td>\n",
              "      <td>91.644516</td>\n",
              "      <td>-17.487844</td>\n",
              "      <td>62.793236</td>\n",
              "      <td>24.189877</td>\n",
              "      <td>71.165848</td>\n",
              "      <td>-24.778721</td>\n",
              "      <td>75.783257</td>\n",
              "      <td>17.113907</td>\n",
              "      <td>59.456768</td>\n",
              "      <td>-15.878265</td>\n",
              "      <td>52.452339</td>\n",
              "      <td>10.379856</td>\n",
              "      <td>49.631775</td>\n",
              "      <td>-8.625669</td>\n",
              "      <td>38.654865</td>\n",
              "      <td>7.147680</td>\n",
              "      <td>43.124485</td>\n",
              "      <td>-11.835875</td>\n",
              "      <td>36.092770</td>\n",
              "      <td>3.169227</td>\n",
              "      <td>31.910709</td>\n",
              "      <td>-10.361743</td>\n",
              "      <td>31.489822</td>\n",
              "      <td>1.505117</td>\n",
              "      <td>33.656353</td>\n",
              "      <td>-10.361339</td>\n",
              "      <td>40.228825</td>\n",
              "      <td>-2.480384</td>\n",
              "      <td>31.079451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>0.485229</td>\n",
              "      <td>0.076683</td>\n",
              "      <td>0.090661</td>\n",
              "      <td>0.002879</td>\n",
              "      <td>2574.454343</td>\n",
              "      <td>4.329060e+05</td>\n",
              "      <td>2396.480081</td>\n",
              "      <td>95966.324238</td>\n",
              "      <td>5458.450494</td>\n",
              "      <td>1.468582e+06</td>\n",
              "      <td>0.146114</td>\n",
              "      <td>0.004204</td>\n",
              "      <td>4.288645e-06</td>\n",
              "      <td>0.002570</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.005762</td>\n",
              "      <td>129.199219</td>\n",
              "      <td>-125.637733</td>\n",
              "      <td>1863.019775</td>\n",
              "      <td>88.535866</td>\n",
              "      <td>583.760925</td>\n",
              "      <td>-16.749247</td>\n",
              "      <td>353.307709</td>\n",
              "      <td>42.787514</td>\n",
              "      <td>206.633942</td>\n",
              "      <td>-9.902900</td>\n",
              "      <td>120.206764</td>\n",
              "      <td>29.152266</td>\n",
              "      <td>102.768456</td>\n",
              "      <td>-19.360279</td>\n",
              "      <td>92.861015</td>\n",
              "      <td>20.458952</td>\n",
              "      <td>68.858864</td>\n",
              "      <td>-16.478580</td>\n",
              "      <td>65.399033</td>\n",
              "      <td>15.016833</td>\n",
              "      <td>55.853935</td>\n",
              "      <td>-8.755143</td>\n",
              "      <td>53.490120</td>\n",
              "      <td>12.770605</td>\n",
              "      <td>45.578686</td>\n",
              "      <td>-7.753715</td>\n",
              "      <td>41.017509</td>\n",
              "      <td>7.039320</td>\n",
              "      <td>42.877178</td>\n",
              "      <td>-8.515849</td>\n",
              "      <td>33.040672</td>\n",
              "      <td>3.272150</td>\n",
              "      <td>32.648281</td>\n",
              "      <td>-6.473699</td>\n",
              "      <td>43.241314</td>\n",
              "      <td>5.798188</td>\n",
              "      <td>31.986368</td>\n",
              "      <td>-3.494546</td>\n",
              "      <td>35.222599</td>\n",
              "      <td>-0.060173</td>\n",
              "      <td>35.280766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>0.485227</td>\n",
              "      <td>0.086623</td>\n",
              "      <td>0.115639</td>\n",
              "      <td>0.003476</td>\n",
              "      <td>2908.392061</td>\n",
              "      <td>1.492491e+06</td>\n",
              "      <td>2990.066467</td>\n",
              "      <td>268903.685905</td>\n",
              "      <td>6346.674306</td>\n",
              "      <td>4.513541e+06</td>\n",
              "      <td>0.101183</td>\n",
              "      <td>0.005515</td>\n",
              "      <td>3.993860e-06</td>\n",
              "      <td>0.005667</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>0.006574</td>\n",
              "      <td>112.347147</td>\n",
              "      <td>-155.792068</td>\n",
              "      <td>6614.249023</td>\n",
              "      <td>60.578403</td>\n",
              "      <td>1233.582764</td>\n",
              "      <td>23.198116</td>\n",
              "      <td>1421.363525</td>\n",
              "      <td>31.210896</td>\n",
              "      <td>319.673828</td>\n",
              "      <td>25.073206</td>\n",
              "      <td>263.085083</td>\n",
              "      <td>16.914068</td>\n",
              "      <td>152.383820</td>\n",
              "      <td>9.436687</td>\n",
              "      <td>116.897209</td>\n",
              "      <td>8.456102</td>\n",
              "      <td>120.772285</td>\n",
              "      <td>5.326895</td>\n",
              "      <td>95.257248</td>\n",
              "      <td>6.556581</td>\n",
              "      <td>62.313141</td>\n",
              "      <td>5.768651</td>\n",
              "      <td>87.170013</td>\n",
              "      <td>3.919316</td>\n",
              "      <td>56.489960</td>\n",
              "      <td>7.570214</td>\n",
              "      <td>67.256432</td>\n",
              "      <td>2.174764</td>\n",
              "      <td>44.640251</td>\n",
              "      <td>4.426754</td>\n",
              "      <td>54.177868</td>\n",
              "      <td>4.349401</td>\n",
              "      <td>47.346210</td>\n",
              "      <td>-0.011641</td>\n",
              "      <td>39.905415</td>\n",
              "      <td>0.893014</td>\n",
              "      <td>45.626076</td>\n",
              "      <td>-0.482778</td>\n",
              "      <td>39.424004</td>\n",
              "      <td>-4.772405</td>\n",
              "      <td>44.106415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>0.401963</td>\n",
              "      <td>0.093053</td>\n",
              "      <td>0.101107</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>2009.585992</td>\n",
              "      <td>4.913864e+05</td>\n",
              "      <td>2141.377602</td>\n",
              "      <td>179690.822659</td>\n",
              "      <td>4304.667164</td>\n",
              "      <td>2.404195e+06</td>\n",
              "      <td>0.084453</td>\n",
              "      <td>0.002418</td>\n",
              "      <td>5.092938e-08</td>\n",
              "      <td>0.005747</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>0.004087</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-175.551208</td>\n",
              "      <td>7050.454102</td>\n",
              "      <td>104.886215</td>\n",
              "      <td>876.035767</td>\n",
              "      <td>-15.680851</td>\n",
              "      <td>559.010315</td>\n",
              "      <td>27.523685</td>\n",
              "      <td>375.714569</td>\n",
              "      <td>-8.108690</td>\n",
              "      <td>244.351212</td>\n",
              "      <td>24.019665</td>\n",
              "      <td>199.264557</td>\n",
              "      <td>-10.319920</td>\n",
              "      <td>256.314545</td>\n",
              "      <td>18.858122</td>\n",
              "      <td>186.938950</td>\n",
              "      <td>-8.376987</td>\n",
              "      <td>184.392792</td>\n",
              "      <td>11.853949</td>\n",
              "      <td>159.177200</td>\n",
              "      <td>-7.580990</td>\n",
              "      <td>134.740768</td>\n",
              "      <td>12.563684</td>\n",
              "      <td>126.334496</td>\n",
              "      <td>-6.032728</td>\n",
              "      <td>95.468475</td>\n",
              "      <td>2.497778</td>\n",
              "      <td>116.083893</td>\n",
              "      <td>1.900042</td>\n",
              "      <td>84.962547</td>\n",
              "      <td>7.134636</td>\n",
              "      <td>84.130760</td>\n",
              "      <td>-3.370105</td>\n",
              "      <td>86.956825</td>\n",
              "      <td>12.441627</td>\n",
              "      <td>93.374908</td>\n",
              "      <td>-3.351832</td>\n",
              "      <td>70.833794</td>\n",
              "      <td>0.741723</td>\n",
              "      <td>89.512894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>0.367162</td>\n",
              "      <td>0.085361</td>\n",
              "      <td>0.197023</td>\n",
              "      <td>0.004277</td>\n",
              "      <td>2515.462487</td>\n",
              "      <td>2.725576e+05</td>\n",
              "      <td>2531.268049</td>\n",
              "      <td>66563.316920</td>\n",
              "      <td>5770.931745</td>\n",
              "      <td>9.979541e+05</td>\n",
              "      <td>0.120890</td>\n",
              "      <td>0.001670</td>\n",
              "      <td>-2.072069e-06</td>\n",
              "      <td>0.019942</td>\n",
              "      <td>-0.000019</td>\n",
              "      <td>0.010110</td>\n",
              "      <td>112.347147</td>\n",
              "      <td>-55.976925</td>\n",
              "      <td>2862.485596</td>\n",
              "      <td>87.847710</td>\n",
              "      <td>358.029266</td>\n",
              "      <td>-1.610706</td>\n",
              "      <td>288.238220</td>\n",
              "      <td>41.199081</td>\n",
              "      <td>165.712677</td>\n",
              "      <td>-5.617903</td>\n",
              "      <td>140.059540</td>\n",
              "      <td>27.789429</td>\n",
              "      <td>108.688904</td>\n",
              "      <td>-23.989286</td>\n",
              "      <td>91.703270</td>\n",
              "      <td>21.777727</td>\n",
              "      <td>64.954742</td>\n",
              "      <td>-18.419083</td>\n",
              "      <td>85.355759</td>\n",
              "      <td>12.323682</td>\n",
              "      <td>65.808372</td>\n",
              "      <td>-13.712481</td>\n",
              "      <td>65.585457</td>\n",
              "      <td>11.851964</td>\n",
              "      <td>70.848816</td>\n",
              "      <td>-3.971119</td>\n",
              "      <td>58.672993</td>\n",
              "      <td>7.099814</td>\n",
              "      <td>88.073868</td>\n",
              "      <td>-4.467886</td>\n",
              "      <td>57.207355</td>\n",
              "      <td>5.117015</td>\n",
              "      <td>55.989697</td>\n",
              "      <td>-6.643124</td>\n",
              "      <td>59.674076</td>\n",
              "      <td>5.867205</td>\n",
              "      <td>53.886051</td>\n",
              "      <td>-3.704879</td>\n",
              "      <td>67.698318</td>\n",
              "      <td>-1.961424</td>\n",
              "      <td>69.034843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>0.225919</td>\n",
              "      <td>0.086109</td>\n",
              "      <td>0.044768</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>2192.650290</td>\n",
              "      <td>1.289134e+05</td>\n",
              "      <td>1911.826157</td>\n",
              "      <td>27709.483168</td>\n",
              "      <td>4066.011660</td>\n",
              "      <td>3.900321e+05</td>\n",
              "      <td>0.152405</td>\n",
              "      <td>0.002071</td>\n",
              "      <td>-6.319842e-04</td>\n",
              "      <td>0.002079</td>\n",
              "      <td>-0.000484</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>92.285156</td>\n",
              "      <td>-251.226730</td>\n",
              "      <td>3228.770752</td>\n",
              "      <td>88.745979</td>\n",
              "      <td>229.556656</td>\n",
              "      <td>-41.787323</td>\n",
              "      <td>145.430847</td>\n",
              "      <td>37.920158</td>\n",
              "      <td>65.844841</td>\n",
              "      <td>-12.033498</td>\n",
              "      <td>112.384972</td>\n",
              "      <td>21.634789</td>\n",
              "      <td>79.783203</td>\n",
              "      <td>-5.862582</td>\n",
              "      <td>129.148605</td>\n",
              "      <td>25.715189</td>\n",
              "      <td>132.678223</td>\n",
              "      <td>-5.211888</td>\n",
              "      <td>213.568756</td>\n",
              "      <td>14.296337</td>\n",
              "      <td>207.537384</td>\n",
              "      <td>-7.554204</td>\n",
              "      <td>243.560501</td>\n",
              "      <td>10.476006</td>\n",
              "      <td>217.692291</td>\n",
              "      <td>-4.916656</td>\n",
              "      <td>234.819000</td>\n",
              "      <td>5.282159</td>\n",
              "      <td>163.205017</td>\n",
              "      <td>0.297458</td>\n",
              "      <td>90.371231</td>\n",
              "      <td>3.327214</td>\n",
              "      <td>56.191154</td>\n",
              "      <td>1.267257</td>\n",
              "      <td>68.573349</td>\n",
              "      <td>4.770478</td>\n",
              "      <td>109.475929</td>\n",
              "      <td>-2.081254</td>\n",
              "      <td>121.208862</td>\n",
              "      <td>1.126511</td>\n",
              "      <td>188.134552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0.344511</td>\n",
              "      <td>0.085002</td>\n",
              "      <td>0.046747</td>\n",
              "      <td>0.001542</td>\n",
              "      <td>1503.869486</td>\n",
              "      <td>5.545765e+05</td>\n",
              "      <td>1754.216082</td>\n",
              "      <td>283554.933422</td>\n",
              "      <td>2799.283099</td>\n",
              "      <td>2.685679e+06</td>\n",
              "      <td>0.078417</td>\n",
              "      <td>0.002446</td>\n",
              "      <td>-4.445727e-04</td>\n",
              "      <td>0.001813</td>\n",
              "      <td>-0.000502</td>\n",
              "      <td>0.000754</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-252.073181</td>\n",
              "      <td>12152.553711</td>\n",
              "      <td>137.903198</td>\n",
              "      <td>1465.569092</td>\n",
              "      <td>-11.130972</td>\n",
              "      <td>731.742676</td>\n",
              "      <td>8.365116</td>\n",
              "      <td>120.025108</td>\n",
              "      <td>0.730073</td>\n",
              "      <td>117.530769</td>\n",
              "      <td>1.590433</td>\n",
              "      <td>53.199692</td>\n",
              "      <td>-3.729430</td>\n",
              "      <td>56.258579</td>\n",
              "      <td>-4.132516</td>\n",
              "      <td>38.233238</td>\n",
              "      <td>-5.499070</td>\n",
              "      <td>43.664577</td>\n",
              "      <td>-2.634166</td>\n",
              "      <td>37.596851</td>\n",
              "      <td>-3.537999</td>\n",
              "      <td>43.037212</td>\n",
              "      <td>-3.147690</td>\n",
              "      <td>59.072803</td>\n",
              "      <td>-1.849362</td>\n",
              "      <td>43.804523</td>\n",
              "      <td>-1.001880</td>\n",
              "      <td>41.195480</td>\n",
              "      <td>-2.580429</td>\n",
              "      <td>48.979965</td>\n",
              "      <td>-1.957420</td>\n",
              "      <td>50.311016</td>\n",
              "      <td>-1.503434</td>\n",
              "      <td>41.141155</td>\n",
              "      <td>0.221949</td>\n",
              "      <td>55.707256</td>\n",
              "      <td>-1.991485</td>\n",
              "      <td>50.006485</td>\n",
              "      <td>-3.353825</td>\n",
              "      <td>49.906403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 57 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     chroma_stft_mean  chroma_stft_var  ...  mfcc20_mean  mfcc20_var\n",
              "723          0.393456         0.095185  ...    -0.377610   92.051102\n",
              "471          0.403845         0.099548  ...    -2.477071   34.385494\n",
              "956          0.488327         0.072437  ...     0.505033   25.160053\n",
              "968          0.401931         0.082724  ...    -2.480384   31.079451\n",
              "390          0.485229         0.076683  ...    -0.060173   35.280766\n",
              "..                ...              ...  ...          ...         ...\n",
              "327          0.485227         0.086623  ...    -4.772405   44.106415\n",
              "804          0.401963         0.093053  ...     0.741723   89.512894\n",
              "74           0.367162         0.085361  ...    -1.961424   69.034843\n",
              "191          0.225919         0.086109  ...     1.126511  188.134552\n",
              "500          0.344511         0.085002  ...    -3.353825   49.906403\n",
              "\n",
              "[1000 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC43roVl-Ghd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize X\n",
        "\n",
        "def normalize(X) :\n",
        "  epsilon = np.power([10.0], -7)\n",
        "  n, m = np.shape(X)\n",
        "  mu = (1 / m) * np.mean(X)\n",
        "  sigma_sq = (1 / m) * np.sum(np.power(X, 2))\n",
        "  X = (X - mu) / (sigma_sq + epsilon)\n",
        "  return X\n",
        "\n",
        "df_X = normalize(df_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQjoJgtxI1vl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "e80f3242-5e25-4e7d-af34-99d7f248a77e"
      },
      "source": [
        "df_X"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>rms_mean</th>\n",
              "      <th>rms_var</th>\n",
              "      <th>spectral_centroid_mean</th>\n",
              "      <th>spectral_centroid_var</th>\n",
              "      <th>spectral_bandwidth_mean</th>\n",
              "      <th>spectral_bandwidth_var</th>\n",
              "      <th>rolloff_mean</th>\n",
              "      <th>rolloff_var</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_var</th>\n",
              "      <th>harmony_mean</th>\n",
              "      <th>harmony_var</th>\n",
              "      <th>perceptr_mean</th>\n",
              "      <th>perceptr_var</th>\n",
              "      <th>tempo</th>\n",
              "      <th>mfcc1_mean</th>\n",
              "      <th>mfcc1_var</th>\n",
              "      <th>mfcc2_mean</th>\n",
              "      <th>mfcc2_var</th>\n",
              "      <th>mfcc3_mean</th>\n",
              "      <th>mfcc3_var</th>\n",
              "      <th>mfcc4_mean</th>\n",
              "      <th>mfcc4_var</th>\n",
              "      <th>mfcc5_mean</th>\n",
              "      <th>mfcc5_var</th>\n",
              "      <th>mfcc6_mean</th>\n",
              "      <th>mfcc6_var</th>\n",
              "      <th>mfcc7_mean</th>\n",
              "      <th>mfcc7_var</th>\n",
              "      <th>mfcc8_mean</th>\n",
              "      <th>mfcc8_var</th>\n",
              "      <th>mfcc9_mean</th>\n",
              "      <th>mfcc9_var</th>\n",
              "      <th>mfcc10_mean</th>\n",
              "      <th>mfcc10_var</th>\n",
              "      <th>mfcc11_mean</th>\n",
              "      <th>mfcc11_var</th>\n",
              "      <th>mfcc12_mean</th>\n",
              "      <th>mfcc12_var</th>\n",
              "      <th>mfcc13_mean</th>\n",
              "      <th>mfcc13_var</th>\n",
              "      <th>mfcc14_mean</th>\n",
              "      <th>mfcc14_var</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "      <th>mfcc20_mean</th>\n",
              "      <th>mfcc20_var</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>0.146921</td>\n",
              "      <td>0.710537</td>\n",
              "      <td>0.554044</td>\n",
              "      <td>18.230495</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>2.171477e-07</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>3.602841e-07</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>3.351411e-08</td>\n",
              "      <td>0.802499</td>\n",
              "      <td>31.585282</td>\n",
              "      <td>0.150107</td>\n",
              "      <td>3.042711</td>\n",
              "      <td>-4.028254</td>\n",
              "      <td>16.194620</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>-0.000077</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.002607</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>0.004125</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>0.001184</td>\n",
              "      <td>0.000535</td>\n",
              "      <td>0.003786</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>-0.000252</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.002948</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.002147</td>\n",
              "      <td>0.000631</td>\n",
              "      <td>-0.001656</td>\n",
              "      <td>0.000552</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.000691</td>\n",
              "      <td>-0.001750</td>\n",
              "      <td>0.000682</td>\n",
              "      <td>-0.000984</td>\n",
              "      <td>0.000604</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>0.000634</td>\n",
              "      <td>-0.005177</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>-0.002970</td>\n",
              "      <td>0.000761</td>\n",
              "      <td>-0.003913</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>0.000545</td>\n",
              "      <td>-0.001284</td>\n",
              "      <td>0.000744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>0.150867</td>\n",
              "      <td>0.743629</td>\n",
              "      <td>0.650268</td>\n",
              "      <td>20.621235</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.986537e-07</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>2.305189e-07</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>2.350855e-08</td>\n",
              "      <td>0.482629</td>\n",
              "      <td>31.271601</td>\n",
              "      <td>0.110501</td>\n",
              "      <td>7.599769</td>\n",
              "      <td>-6.696461</td>\n",
              "      <td>9.985361</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>-0.000141</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.007613</td>\n",
              "      <td>0.000313</td>\n",
              "      <td>0.001080</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.003701</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.001805</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>-0.002184</td>\n",
              "      <td>0.000671</td>\n",
              "      <td>0.001639</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.002579</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.003729</td>\n",
              "      <td>0.000682</td>\n",
              "      <td>0.002512</td>\n",
              "      <td>0.000717</td>\n",
              "      <td>0.001475</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>-0.013390</td>\n",
              "      <td>0.000755</td>\n",
              "      <td>-0.005590</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>-0.004086</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>-0.020753</td>\n",
              "      <td>0.000355</td>\n",
              "      <td>-0.003761</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>-0.008807</td>\n",
              "      <td>0.000271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>0.182956</td>\n",
              "      <td>0.537981</td>\n",
              "      <td>0.460870</td>\n",
              "      <td>5.054512</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>6.775261e-08</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>1.520493e-07</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1.279749e-08</td>\n",
              "      <td>0.802371</td>\n",
              "      <td>14.559599</td>\n",
              "      <td>2.874558</td>\n",
              "      <td>2.630847</td>\n",
              "      <td>102.172301</td>\n",
              "      <td>5.743843</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>-0.000010</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.001014</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.001206</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.001997</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>-0.000622</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.001316</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.002870</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>-0.000724</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.001074</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>-0.006216</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>-0.001393</td>\n",
              "      <td>0.000473</td>\n",
              "      <td>-0.001828</td>\n",
              "      <td>0.000332</td>\n",
              "      <td>-0.000958</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>0.005678</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>-0.001212</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.001878</td>\n",
              "      <td>0.000196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>968</th>\n",
              "      <td>0.150141</td>\n",
              "      <td>0.616009</td>\n",
              "      <td>0.236252</td>\n",
              "      <td>1.266652</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>4.101163e-08</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>8.580097e-08</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>7.949003e-09</td>\n",
              "      <td>0.531779</td>\n",
              "      <td>7.880793</td>\n",
              "      <td>-28.850042</td>\n",
              "      <td>0.856181</td>\n",
              "      <td>-91.708342</td>\n",
              "      <td>1.378693</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>-0.000219</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>-0.001510</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.001870</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>-0.004314</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>-0.007932</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.006463</td>\n",
              "      <td>0.000419</td>\n",
              "      <td>-0.011964</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.007888</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>-0.010874</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>0.009026</td>\n",
              "      <td>0.000478</td>\n",
              "      <td>-0.007977</td>\n",
              "      <td>0.000374</td>\n",
              "      <td>0.014367</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>-0.017333</td>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.008062</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>-0.016113</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.005606</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>-0.030142</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>-0.008819</td>\n",
              "      <td>0.000244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>0.181779</td>\n",
              "      <td>0.570187</td>\n",
              "      <td>0.234786</td>\n",
              "      <td>7.152555</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>6.350436e-08</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>1.898873e-07</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>1.507517e-08</td>\n",
              "      <td>0.658898</td>\n",
              "      <td>13.105187</td>\n",
              "      <td>0.205348</td>\n",
              "      <td>0.457326</td>\n",
              "      <td>2.580630</td>\n",
              "      <td>4.340502</td>\n",
              "      <td>0.000480</td>\n",
              "      <td>-0.000227</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>-0.001721</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.001507</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>-0.003742</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.004650</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>-0.008786</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.005459</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>-0.007936</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.006914</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>-0.005963</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.011121</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>-0.007163</td>\n",
              "      <td>0.000398</td>\n",
              "      <td>0.014148</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>-0.012443</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.008326</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>-0.010026</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>0.021692</td>\n",
              "      <td>0.000336</td>\n",
              "      <td>-0.010087</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>-0.000147</td>\n",
              "      <td>0.000279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>0.181778</td>\n",
              "      <td>0.645588</td>\n",
              "      <td>0.301152</td>\n",
              "      <td>8.665367</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>2.219543e-07</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>5.408718e-07</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>4.703621e-08</td>\n",
              "      <td>0.453732</td>\n",
              "      <td>17.246831</td>\n",
              "      <td>0.199695</td>\n",
              "      <td>1.059948</td>\n",
              "      <td>-0.153840</td>\n",
              "      <td>4.962186</td>\n",
              "      <td>0.000417</td>\n",
              "      <td>-0.000283</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>0.009502</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.002681</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.004343</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>0.002228</td>\n",
              "      <td>0.000718</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>0.000568</td>\n",
              "      <td>0.002983</td>\n",
              "      <td>0.000432</td>\n",
              "      <td>0.004050</td>\n",
              "      <td>0.000683</td>\n",
              "      <td>0.003365</td>\n",
              "      <td>0.000545</td>\n",
              "      <td>0.007148</td>\n",
              "      <td>0.000660</td>\n",
              "      <td>0.004327</td>\n",
              "      <td>0.000461</td>\n",
              "      <td>0.006620</td>\n",
              "      <td>0.000593</td>\n",
              "      <td>0.011084</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>0.003313</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>-0.001291</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>-0.017031</td>\n",
              "      <td>0.000351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>0.150153</td>\n",
              "      <td>0.694362</td>\n",
              "      <td>0.262540</td>\n",
              "      <td>6.782588</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>7.224950e-08</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>3.598101e-07</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>2.489571e-08</td>\n",
              "      <td>0.377338</td>\n",
              "      <td>7.468900</td>\n",
              "      <td>0.124085</td>\n",
              "      <td>1.075548</td>\n",
              "      <td>-0.712585</td>\n",
              "      <td>3.056076</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>-0.000319</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>-0.001610</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.000961</td>\n",
              "      <td>0.000341</td>\n",
              "      <td>-0.003063</td>\n",
              "      <td>0.000339</td>\n",
              "      <td>0.003824</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>-0.004664</td>\n",
              "      <td>0.000855</td>\n",
              "      <td>0.005028</td>\n",
              "      <td>0.001117</td>\n",
              "      <td>-0.004005</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>0.005444</td>\n",
              "      <td>0.001120</td>\n",
              "      <td>-0.005154</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>0.010940</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>-0.005555</td>\n",
              "      <td>0.000942</td>\n",
              "      <td>0.004980</td>\n",
              "      <td>0.001218</td>\n",
              "      <td>0.002899</td>\n",
              "      <td>0.000937</td>\n",
              "      <td>0.018214</td>\n",
              "      <td>0.000981</td>\n",
              "      <td>-0.005167</td>\n",
              "      <td>0.000970</td>\n",
              "      <td>0.046584</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>-0.009670</td>\n",
              "      <td>0.000689</td>\n",
              "      <td>0.002727</td>\n",
              "      <td>0.000723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>0.136934</td>\n",
              "      <td>0.636013</td>\n",
              "      <td>0.517393</td>\n",
              "      <td>10.694068</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>3.952592e-08</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>1.302125e-07</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>1.013527e-08</td>\n",
              "      <td>0.543721</td>\n",
              "      <td>5.106248</td>\n",
              "      <td>0.083374</td>\n",
              "      <td>3.837808</td>\n",
              "      <td>-0.527951</td>\n",
              "      <td>7.672532</td>\n",
              "      <td>0.000417</td>\n",
              "      <td>-0.000099</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000451</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>-0.000151</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.001450</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>-0.002120</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.004431</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>-0.010896</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.005814</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>-0.008878</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.005663</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>-0.009381</td>\n",
              "      <td>0.000512</td>\n",
              "      <td>0.010316</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>-0.003630</td>\n",
              "      <td>0.000574</td>\n",
              "      <td>0.014270</td>\n",
              "      <td>0.000921</td>\n",
              "      <td>-0.006481</td>\n",
              "      <td>0.000627</td>\n",
              "      <td>0.013049</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>-0.010291</td>\n",
              "      <td>0.000662</td>\n",
              "      <td>0.021950</td>\n",
              "      <td>0.000574</td>\n",
              "      <td>-0.010701</td>\n",
              "      <td>0.000658</td>\n",
              "      <td>-0.006959</td>\n",
              "      <td>0.000555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>0.083286</td>\n",
              "      <td>0.641686</td>\n",
              "      <td>0.112846</td>\n",
              "      <td>0.866509</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>1.804542e-08</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>5.135684e-08</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>3.754294e-09</td>\n",
              "      <td>0.687628</td>\n",
              "      <td>6.372707</td>\n",
              "      <td>-11.995908</td>\n",
              "      <td>0.361696</td>\n",
              "      <td>-20.433649</td>\n",
              "      <td>-0.021795</td>\n",
              "      <td>0.000341</td>\n",
              "      <td>-0.000459</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000455</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>-0.004318</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.001333</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>-0.004549</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.003441</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>-0.002632</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.006874</td>\n",
              "      <td>0.000790</td>\n",
              "      <td>-0.002469</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.001463</td>\n",
              "      <td>-0.005135</td>\n",
              "      <td>0.001928</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.002135</td>\n",
              "      <td>-0.004513</td>\n",
              "      <td>0.002334</td>\n",
              "      <td>0.010601</td>\n",
              "      <td>0.001717</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>0.000997</td>\n",
              "      <td>0.008467</td>\n",
              "      <td>0.000651</td>\n",
              "      <td>0.002093</td>\n",
              "      <td>0.000763</td>\n",
              "      <td>0.017841</td>\n",
              "      <td>0.001178</td>\n",
              "      <td>-0.005959</td>\n",
              "      <td>0.001186</td>\n",
              "      <td>0.004105</td>\n",
              "      <td>0.001530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0.128331</td>\n",
              "      <td>0.633293</td>\n",
              "      <td>0.118104</td>\n",
              "      <td>3.769759</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>8.169893e-08</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>5.706072e-07</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>2.785027e-08</td>\n",
              "      <td>0.349773</td>\n",
              "      <td>7.556092</td>\n",
              "      <td>-8.402078</td>\n",
              "      <td>0.310007</td>\n",
              "      <td>-21.207383</td>\n",
              "      <td>0.501730</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>-0.000460</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000713</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>-0.001138</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>-0.001659</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>-0.001160</td>\n",
              "      <td>0.000221</td>\n",
              "      <td>-0.002609</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>-0.001287</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>-0.002366</td>\n",
              "      <td>0.000332</td>\n",
              "      <td>-0.002827</td>\n",
              "      <td>0.000571</td>\n",
              "      <td>-0.001649</td>\n",
              "      <td>0.000426</td>\n",
              "      <td>-0.002086</td>\n",
              "      <td>0.000424</td>\n",
              "      <td>-0.003701</td>\n",
              "      <td>0.000535</td>\n",
              "      <td>-0.005063</td>\n",
              "      <td>0.000581</td>\n",
              "      <td>-0.002245</td>\n",
              "      <td>0.000453</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>0.000594</td>\n",
              "      <td>-0.005697</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>-0.011948</td>\n",
              "      <td>0.000399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 57 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     chroma_stft_mean  chroma_stft_var  ...  mfcc20_mean  mfcc20_var\n",
              "723          0.146921         0.710537  ...    -0.001284    0.000744\n",
              "471          0.150867         0.743629  ...    -0.008807    0.000271\n",
              "956          0.182956         0.537981  ...     0.001878    0.000196\n",
              "968          0.150141         0.616009  ...    -0.008819    0.000244\n",
              "390          0.181779         0.570187  ...    -0.000147    0.000279\n",
              "..                ...              ...  ...          ...         ...\n",
              "327          0.181778         0.645588  ...    -0.017031    0.000351\n",
              "804          0.150153         0.694362  ...     0.002727    0.000723\n",
              "74           0.136934         0.636013  ...    -0.006959    0.000555\n",
              "191          0.083286         0.641686  ...     0.004105    0.001530\n",
              "500          0.128331         0.633293  ...    -0.011948    0.000399\n",
              "\n",
              "[1000 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZvoahnwTeqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct a dictionary from all the possible labels in Y\n",
        "dictLabels = dict(map(reversed, enumerate(list(set(df_Y_raw['label'])))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya_x59H8OzSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset into train, dev and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.4, shuffle=False)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=False)\n",
        "\n",
        "# One-hot encode the y sets\n",
        "s = pd.Series(dictLabels)\n",
        "y_train = keras.utils.to_categorical(s[y_train['label']])\n",
        "y_dev = keras.utils.to_categorical(s[y_dev['label']])\n",
        "y_test = keras.utils.to_categorical(s[y_test['label']])\n",
        "\n",
        "# Transpose all the sets\n",
        "# X_train = X_train.T\n",
        "# X_dev = X_dev.T\n",
        "# X_test = X_test.T\n",
        "# y_train = y_train.T\n",
        "# y_dev = y_dev.T\n",
        "# y_test = y_test.T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV6oejPD8Sns",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZXgBieiHl51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the shape of the data\n",
        "m_train, n = np.shape(X_train)\n",
        "m_dev, _ = np.shape(X_dev)\n",
        "m_test, _ = np.shape(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWNjn_miHw1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "cd5263fe-d332-4b59-8035-0fb1cf13ad67"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>rms_mean</th>\n",
              "      <th>rms_var</th>\n",
              "      <th>spectral_centroid_mean</th>\n",
              "      <th>spectral_centroid_var</th>\n",
              "      <th>spectral_bandwidth_mean</th>\n",
              "      <th>spectral_bandwidth_var</th>\n",
              "      <th>rolloff_mean</th>\n",
              "      <th>rolloff_var</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_var</th>\n",
              "      <th>harmony_mean</th>\n",
              "      <th>harmony_var</th>\n",
              "      <th>perceptr_mean</th>\n",
              "      <th>perceptr_var</th>\n",
              "      <th>tempo</th>\n",
              "      <th>mfcc1_mean</th>\n",
              "      <th>mfcc1_var</th>\n",
              "      <th>mfcc2_mean</th>\n",
              "      <th>mfcc2_var</th>\n",
              "      <th>mfcc3_mean</th>\n",
              "      <th>mfcc3_var</th>\n",
              "      <th>mfcc4_mean</th>\n",
              "      <th>mfcc4_var</th>\n",
              "      <th>mfcc5_mean</th>\n",
              "      <th>mfcc5_var</th>\n",
              "      <th>mfcc6_mean</th>\n",
              "      <th>mfcc6_var</th>\n",
              "      <th>mfcc7_mean</th>\n",
              "      <th>mfcc7_var</th>\n",
              "      <th>mfcc8_mean</th>\n",
              "      <th>mfcc8_var</th>\n",
              "      <th>mfcc9_mean</th>\n",
              "      <th>mfcc9_var</th>\n",
              "      <th>mfcc10_mean</th>\n",
              "      <th>mfcc10_var</th>\n",
              "      <th>mfcc11_mean</th>\n",
              "      <th>mfcc11_var</th>\n",
              "      <th>mfcc12_mean</th>\n",
              "      <th>mfcc12_var</th>\n",
              "      <th>mfcc13_mean</th>\n",
              "      <th>mfcc13_var</th>\n",
              "      <th>mfcc14_mean</th>\n",
              "      <th>mfcc14_var</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "      <th>mfcc20_mean</th>\n",
              "      <th>mfcc20_var</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>0.146921</td>\n",
              "      <td>0.710537</td>\n",
              "      <td>0.554044</td>\n",
              "      <td>18.230495</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>2.171477e-07</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>3.602841e-07</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>3.351411e-08</td>\n",
              "      <td>0.802499</td>\n",
              "      <td>31.585282</td>\n",
              "      <td>0.150107</td>\n",
              "      <td>3.042711</td>\n",
              "      <td>-4.028254</td>\n",
              "      <td>16.194620</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>-0.000077</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.002607</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>0.004125</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>0.001184</td>\n",
              "      <td>0.000535</td>\n",
              "      <td>0.003786</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>-0.000252</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.002948</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.002147</td>\n",
              "      <td>0.000631</td>\n",
              "      <td>-0.001656</td>\n",
              "      <td>0.000552</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.000691</td>\n",
              "      <td>-0.001750</td>\n",
              "      <td>0.000682</td>\n",
              "      <td>-0.000984</td>\n",
              "      <td>0.000604</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>0.000634</td>\n",
              "      <td>-0.005177</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>-0.002970</td>\n",
              "      <td>0.000761</td>\n",
              "      <td>-0.003913</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>0.000545</td>\n",
              "      <td>-0.001284</td>\n",
              "      <td>0.000744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>0.150867</td>\n",
              "      <td>0.743629</td>\n",
              "      <td>0.650268</td>\n",
              "      <td>20.621235</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.986537e-07</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>2.305189e-07</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>2.350855e-08</td>\n",
              "      <td>0.482629</td>\n",
              "      <td>31.271601</td>\n",
              "      <td>0.110501</td>\n",
              "      <td>7.599769</td>\n",
              "      <td>-6.696461</td>\n",
              "      <td>9.985361</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>-0.000141</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.007613</td>\n",
              "      <td>0.000313</td>\n",
              "      <td>0.001080</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.003701</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.001805</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>-0.002184</td>\n",
              "      <td>0.000671</td>\n",
              "      <td>0.001639</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.002579</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.003729</td>\n",
              "      <td>0.000682</td>\n",
              "      <td>0.002512</td>\n",
              "      <td>0.000717</td>\n",
              "      <td>0.001475</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>-0.013390</td>\n",
              "      <td>0.000755</td>\n",
              "      <td>-0.005590</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>-0.004086</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>-0.020753</td>\n",
              "      <td>0.000355</td>\n",
              "      <td>-0.003761</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>-0.008807</td>\n",
              "      <td>0.000271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>0.182956</td>\n",
              "      <td>0.537981</td>\n",
              "      <td>0.460870</td>\n",
              "      <td>5.054512</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>6.775261e-08</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>1.520493e-07</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1.279749e-08</td>\n",
              "      <td>0.802371</td>\n",
              "      <td>14.559599</td>\n",
              "      <td>2.874558</td>\n",
              "      <td>2.630847</td>\n",
              "      <td>102.172301</td>\n",
              "      <td>5.743843</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>-0.000010</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.001014</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.001206</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.001997</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>-0.000622</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.001316</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.002870</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>-0.000724</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.001074</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>-0.006216</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>-0.001393</td>\n",
              "      <td>0.000473</td>\n",
              "      <td>-0.001828</td>\n",
              "      <td>0.000332</td>\n",
              "      <td>-0.000958</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>0.005678</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>-0.001212</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.001878</td>\n",
              "      <td>0.000196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>968</th>\n",
              "      <td>0.150141</td>\n",
              "      <td>0.616009</td>\n",
              "      <td>0.236252</td>\n",
              "      <td>1.266652</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>4.101163e-08</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>8.580097e-08</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>7.949003e-09</td>\n",
              "      <td>0.531779</td>\n",
              "      <td>7.880793</td>\n",
              "      <td>-28.850042</td>\n",
              "      <td>0.856181</td>\n",
              "      <td>-91.708342</td>\n",
              "      <td>1.378693</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>-0.000219</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>-0.001510</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.001870</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>-0.004314</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>-0.007932</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.006463</td>\n",
              "      <td>0.000419</td>\n",
              "      <td>-0.011964</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.007888</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>-0.010874</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>0.009026</td>\n",
              "      <td>0.000478</td>\n",
              "      <td>-0.007977</td>\n",
              "      <td>0.000374</td>\n",
              "      <td>0.014367</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>-0.017333</td>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.008062</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>-0.016113</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.005606</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>-0.030142</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>-0.008819</td>\n",
              "      <td>0.000244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>0.181779</td>\n",
              "      <td>0.570187</td>\n",
              "      <td>0.234786</td>\n",
              "      <td>7.152555</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>6.350436e-08</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>1.898873e-07</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>1.507517e-08</td>\n",
              "      <td>0.658898</td>\n",
              "      <td>13.105187</td>\n",
              "      <td>0.205348</td>\n",
              "      <td>0.457326</td>\n",
              "      <td>2.580630</td>\n",
              "      <td>4.340502</td>\n",
              "      <td>0.000480</td>\n",
              "      <td>-0.000227</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>-0.001721</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.001507</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>-0.003742</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.004650</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>-0.008786</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.005459</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>-0.007936</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.006914</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>-0.005963</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.011121</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>-0.007163</td>\n",
              "      <td>0.000398</td>\n",
              "      <td>0.014148</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>-0.012443</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.008326</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>-0.010026</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>0.021692</td>\n",
              "      <td>0.000336</td>\n",
              "      <td>-0.010087</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>-0.000147</td>\n",
              "      <td>0.000279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>0.186731</td>\n",
              "      <td>0.636587</td>\n",
              "      <td>0.573157</td>\n",
              "      <td>48.810095</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>1.700932e-07</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>3.876928e-07</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>3.621794e-08</td>\n",
              "      <td>0.571030</td>\n",
              "      <td>30.559272</td>\n",
              "      <td>0.110157</td>\n",
              "      <td>6.929231</td>\n",
              "      <td>4.014671</td>\n",
              "      <td>10.435935</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>-0.000133</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.001045</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.005710</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>0.000753</td>\n",
              "      <td>0.000473</td>\n",
              "      <td>0.001082</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>0.001575</td>\n",
              "      <td>0.000841</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.003617</td>\n",
              "      <td>0.001091</td>\n",
              "      <td>0.003321</td>\n",
              "      <td>0.000888</td>\n",
              "      <td>0.007201</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>0.004188</td>\n",
              "      <td>0.000805</td>\n",
              "      <td>0.004779</td>\n",
              "      <td>0.000624</td>\n",
              "      <td>-0.002552</td>\n",
              "      <td>0.000684</td>\n",
              "      <td>-0.004319</td>\n",
              "      <td>0.000416</td>\n",
              "      <td>-0.003819</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>-0.014309</td>\n",
              "      <td>0.000446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>0.161883</td>\n",
              "      <td>0.641010</td>\n",
              "      <td>0.373662</td>\n",
              "      <td>11.912028</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>1.948708e-07</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>5.463630e-07</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>4.857047e-08</td>\n",
              "      <td>0.613428</td>\n",
              "      <td>23.492257</td>\n",
              "      <td>0.094622</td>\n",
              "      <td>1.706006</td>\n",
              "      <td>-2.219837</td>\n",
              "      <td>7.216125</td>\n",
              "      <td>0.000417</td>\n",
              "      <td>-0.000169</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000434</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.000462</td>\n",
              "      <td>0.004854</td>\n",
              "      <td>0.000548</td>\n",
              "      <td>-0.000555</td>\n",
              "      <td>0.000566</td>\n",
              "      <td>-0.001743</td>\n",
              "      <td>0.000629</td>\n",
              "      <td>0.000981</td>\n",
              "      <td>0.000843</td>\n",
              "      <td>-0.002907</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>-0.000226</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.001220</td>\n",
              "      <td>-0.004165</td>\n",
              "      <td>0.000848</td>\n",
              "      <td>-0.002728</td>\n",
              "      <td>0.000932</td>\n",
              "      <td>-0.006034</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>-0.004604</td>\n",
              "      <td>0.000949</td>\n",
              "      <td>-0.012653</td>\n",
              "      <td>0.001245</td>\n",
              "      <td>-0.007727</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>0.005151</td>\n",
              "      <td>0.000810</td>\n",
              "      <td>-0.006023</td>\n",
              "      <td>0.000808</td>\n",
              "      <td>-0.007465</td>\n",
              "      <td>0.000452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>0.079766</td>\n",
              "      <td>0.626666</td>\n",
              "      <td>0.024275</td>\n",
              "      <td>0.088145</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>1.545008e-08</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1.232184e-07</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>6.097636e-09</td>\n",
              "      <td>0.337454</td>\n",
              "      <td>1.850197</td>\n",
              "      <td>0.001801</td>\n",
              "      <td>-0.002134</td>\n",
              "      <td>-0.045236</td>\n",
              "      <td>-0.075413</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>-0.002044</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000961</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>-0.002175</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>-0.002962</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.002801</td>\n",
              "      <td>0.000827</td>\n",
              "      <td>0.001684</td>\n",
              "      <td>0.001625</td>\n",
              "      <td>0.006618</td>\n",
              "      <td>0.001539</td>\n",
              "      <td>0.001438</td>\n",
              "      <td>0.002519</td>\n",
              "      <td>0.004535</td>\n",
              "      <td>0.001974</td>\n",
              "      <td>0.004206</td>\n",
              "      <td>0.001423</td>\n",
              "      <td>0.010142</td>\n",
              "      <td>0.001972</td>\n",
              "      <td>0.010657</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.015786</td>\n",
              "      <td>0.001921</td>\n",
              "      <td>0.011321</td>\n",
              "      <td>0.001557</td>\n",
              "      <td>0.014358</td>\n",
              "      <td>0.002426</td>\n",
              "      <td>0.007711</td>\n",
              "      <td>0.002870</td>\n",
              "      <td>0.017746</td>\n",
              "      <td>0.002189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>0.135648</td>\n",
              "      <td>0.615524</td>\n",
              "      <td>0.093673</td>\n",
              "      <td>0.560141</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>1.667405e-08</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>2.080406e-07</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>1.226970e-08</td>\n",
              "      <td>0.282525</td>\n",
              "      <td>1.316522</td>\n",
              "      <td>0.521041</td>\n",
              "      <td>0.146033</td>\n",
              "      <td>5.591761</td>\n",
              "      <td>0.131758</td>\n",
              "      <td>0.000417</td>\n",
              "      <td>-0.000462</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>-0.000571</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.001427</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>-0.002198</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.002919</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>-0.007553</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.003878</td>\n",
              "      <td>0.000326</td>\n",
              "      <td>-0.007295</td>\n",
              "      <td>0.000238</td>\n",
              "      <td>0.003748</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>-0.009502</td>\n",
              "      <td>0.000304</td>\n",
              "      <td>0.007190</td>\n",
              "      <td>0.000497</td>\n",
              "      <td>-0.006740</td>\n",
              "      <td>0.000335</td>\n",
              "      <td>0.010865</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>-0.009197</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>0.007075</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>-0.006513</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>0.000409</td>\n",
              "      <td>-0.004244</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>-0.009038</td>\n",
              "      <td>0.000249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>0.146325</td>\n",
              "      <td>0.631812</td>\n",
              "      <td>0.411053</td>\n",
              "      <td>2.469291</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>5.977950e-08</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>3.508692e-07</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>1.858246e-08</td>\n",
              "      <td>0.560146</td>\n",
              "      <td>5.087156</td>\n",
              "      <td>0.017180</td>\n",
              "      <td>2.808699</td>\n",
              "      <td>0.303604</td>\n",
              "      <td>3.181565</td>\n",
              "      <td>0.000480</td>\n",
              "      <td>-0.000102</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>-0.001210</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.001363</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000903</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>-0.000543</td>\n",
              "      <td>0.000189</td>\n",
              "      <td>0.002622</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>-0.000742</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.004511</td>\n",
              "      <td>0.000384</td>\n",
              "      <td>0.002148</td>\n",
              "      <td>0.000673</td>\n",
              "      <td>0.006508</td>\n",
              "      <td>0.000832</td>\n",
              "      <td>0.001672</td>\n",
              "      <td>0.000739</td>\n",
              "      <td>0.011372</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>-0.000917</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>0.008781</td>\n",
              "      <td>0.000556</td>\n",
              "      <td>0.000324</td>\n",
              "      <td>0.000604</td>\n",
              "      <td>-0.003586</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>-0.007584</td>\n",
              "      <td>0.000534</td>\n",
              "      <td>0.005959</td>\n",
              "      <td>0.000543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows × 57 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     chroma_stft_mean  chroma_stft_var  ...  mfcc20_mean  mfcc20_var\n",
              "723          0.146921         0.710537  ...    -0.001284    0.000744\n",
              "471          0.150867         0.743629  ...    -0.008807    0.000271\n",
              "956          0.182956         0.537981  ...     0.001878    0.000196\n",
              "968          0.150141         0.616009  ...    -0.008819    0.000244\n",
              "390          0.181779         0.570187  ...    -0.000147    0.000279\n",
              "..                ...              ...  ...          ...         ...\n",
              "467          0.186731         0.636587  ...    -0.014309    0.000446\n",
              "872          0.161883         0.641010  ...    -0.007465    0.000452\n",
              "115          0.079766         0.626666  ...     0.017746    0.002189\n",
              "512          0.135648         0.615524  ...    -0.009038    0.000249\n",
              "333          0.146325         0.631812  ...     0.005959    0.000543\n",
              "\n",
              "[600 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP-lh4CrwjWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nodes per layer\n",
        "n_layer = [n, 128, 128, 128, 10]\n",
        "\n",
        "# Set up a decaying learning rate\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=False)\n",
        "\n",
        "# Hyperparamerters\n",
        "hparams = {}\n",
        "hparams[\"alpha\"] = lr_schedule #0.0001              # Learning rate\n",
        "hparams[\"batch_size\"] = 32              # Mini-batch size\n",
        "hparams[\"epochs\"] = 1000                 # Training epochs\n",
        "hparams[\"L\"] = len(n_layer)             # Number of layers in the model\n",
        "hparams[\"momentum\"] = 0.9             # momentum for SGD\n",
        "hparams[\"nesterov\"] = True           # use Nesterov momentum?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okifwjzquppf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "ce0174a5-6d0a-479a-9cd7-c990ed06a1cb"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(input_shape=(n_layer[0],),activation='relu',units=n_layer[0]))\n",
        "for l in range(1, (hparams[\"L\"] - 1)):\n",
        "  model.add(Dense(activation='relu',units=n_layer[l]))\n",
        "model.add(Dense(activation='softmax',units=n_layer[hparams[\"L\"] - 1]))\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 57)                3306      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               7424      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 45,044\n",
            "Trainable params: 45,044\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJhYza3ky_sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(\n",
        "        learning_rate=hparams[\"alpha\"], \n",
        "        momentum=hparams[\"momentum\"], \n",
        "        nesterov=hparams[\"nesterov\"]), \n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RfgoPUW8X1o",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNDgoRHc1QGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99276594-0d4a-46ef-a269-ad6c009d0764"
      },
      "source": [
        "history = model.fit(X_train,y_train,batch_size=hparams[\"batch_size\"],epochs=hparams[\"epochs\"],verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "600/600 [==============================] - 0s 597us/step - loss: 2.5727 - accuracy: 0.0900\n",
            "Epoch 2/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 2.1655 - accuracy: 0.1450\n",
            "Epoch 3/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 2.0856 - accuracy: 0.1717\n",
            "Epoch 4/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 2.0452 - accuracy: 0.1917\n",
            "Epoch 5/1000\n",
            "600/600 [==============================] - 0s 90us/step - loss: 2.0035 - accuracy: 0.2183\n",
            "Epoch 6/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 1.9844 - accuracy: 0.2250\n",
            "Epoch 7/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 1.9531 - accuracy: 0.2450\n",
            "Epoch 8/1000\n",
            "600/600 [==============================] - 0s 97us/step - loss: 1.9301 - accuracy: 0.2583\n",
            "Epoch 9/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 1.9265 - accuracy: 0.2983\n",
            "Epoch 10/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.8889 - accuracy: 0.2933\n",
            "Epoch 11/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.8709 - accuracy: 0.3150\n",
            "Epoch 12/1000\n",
            "600/600 [==============================] - 0s 86us/step - loss: 1.8382 - accuracy: 0.3383\n",
            "Epoch 13/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.8448 - accuracy: 0.3783\n",
            "Epoch 14/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 1.8057 - accuracy: 0.3617\n",
            "Epoch 15/1000\n",
            "600/600 [==============================] - 0s 84us/step - loss: 1.7800 - accuracy: 0.3883\n",
            "Epoch 16/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 1.7844 - accuracy: 0.4100\n",
            "Epoch 17/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.7636 - accuracy: 0.4000\n",
            "Epoch 18/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.7588 - accuracy: 0.4083\n",
            "Epoch 19/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.7418 - accuracy: 0.4167\n",
            "Epoch 20/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 1.7203 - accuracy: 0.4217\n",
            "Epoch 21/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 1.7223 - accuracy: 0.4300\n",
            "Epoch 22/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 1.6821 - accuracy: 0.4300\n",
            "Epoch 23/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 1.6694 - accuracy: 0.4567\n",
            "Epoch 24/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.6724 - accuracy: 0.4617\n",
            "Epoch 25/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.6551 - accuracy: 0.4467\n",
            "Epoch 26/1000\n",
            "600/600 [==============================] - 0s 86us/step - loss: 1.6173 - accuracy: 0.4817\n",
            "Epoch 27/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.6029 - accuracy: 0.4850\n",
            "Epoch 28/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.5800 - accuracy: 0.5150\n",
            "Epoch 29/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 1.5721 - accuracy: 0.4933\n",
            "Epoch 30/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 1.5624 - accuracy: 0.4983\n",
            "Epoch 31/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.5483 - accuracy: 0.5217\n",
            "Epoch 32/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 1.5249 - accuracy: 0.5450\n",
            "Epoch 33/1000\n",
            "600/600 [==============================] - 0s 89us/step - loss: 1.5182 - accuracy: 0.5133\n",
            "Epoch 34/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 1.4914 - accuracy: 0.5417\n",
            "Epoch 35/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.4913 - accuracy: 0.5283\n",
            "Epoch 36/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.4855 - accuracy: 0.5300\n",
            "Epoch 37/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 1.4600 - accuracy: 0.5350\n",
            "Epoch 38/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.4531 - accuracy: 0.5250\n",
            "Epoch 39/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 1.4210 - accuracy: 0.5700\n",
            "Epoch 40/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.4331 - accuracy: 0.5400\n",
            "Epoch 41/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.4007 - accuracy: 0.5633\n",
            "Epoch 42/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 1.3971 - accuracy: 0.5767\n",
            "Epoch 43/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.4380 - accuracy: 0.5517\n",
            "Epoch 44/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 1.3926 - accuracy: 0.5433\n",
            "Epoch 45/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 1.3923 - accuracy: 0.5400\n",
            "Epoch 46/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 1.3720 - accuracy: 0.5533\n",
            "Epoch 47/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 1.3359 - accuracy: 0.5783\n",
            "Epoch 48/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 1.3569 - accuracy: 0.5617\n",
            "Epoch 49/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.3305 - accuracy: 0.5600\n",
            "Epoch 50/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 1.3184 - accuracy: 0.5733\n",
            "Epoch 51/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 1.3504 - accuracy: 0.5583\n",
            "Epoch 52/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.3362 - accuracy: 0.5633\n",
            "Epoch 53/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.2929 - accuracy: 0.5700\n",
            "Epoch 54/1000\n",
            "600/600 [==============================] - 0s 92us/step - loss: 1.2980 - accuracy: 0.5817\n",
            "Epoch 55/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 1.2748 - accuracy: 0.5983\n",
            "Epoch 56/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 1.2478 - accuracy: 0.5983\n",
            "Epoch 57/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.2397 - accuracy: 0.6050\n",
            "Epoch 58/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 1.2247 - accuracy: 0.5983\n",
            "Epoch 59/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.1948 - accuracy: 0.6050\n",
            "Epoch 60/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 1.2168 - accuracy: 0.6033\n",
            "Epoch 61/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 1.2076 - accuracy: 0.5950\n",
            "Epoch 62/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 1.1858 - accuracy: 0.6083\n",
            "Epoch 63/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 1.1748 - accuracy: 0.6100\n",
            "Epoch 64/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 1.1649 - accuracy: 0.6100\n",
            "Epoch 65/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.1852 - accuracy: 0.6050\n",
            "Epoch 66/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 1.1508 - accuracy: 0.6083\n",
            "Epoch 67/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.1523 - accuracy: 0.6200\n",
            "Epoch 68/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 1.1548 - accuracy: 0.6267\n",
            "Epoch 69/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 1.1700 - accuracy: 0.5950\n",
            "Epoch 70/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 1.1648 - accuracy: 0.5967\n",
            "Epoch 71/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 1.1909 - accuracy: 0.6100\n",
            "Epoch 72/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.1719 - accuracy: 0.5983\n",
            "Epoch 73/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 1.1536 - accuracy: 0.6067\n",
            "Epoch 74/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.1258 - accuracy: 0.6183\n",
            "Epoch 75/1000\n",
            "600/600 [==============================] - 0s 88us/step - loss: 1.1126 - accuracy: 0.6183\n",
            "Epoch 76/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 1.0828 - accuracy: 0.6283\n",
            "Epoch 77/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.0978 - accuracy: 0.6050\n",
            "Epoch 78/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 1.0573 - accuracy: 0.6300\n",
            "Epoch 79/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 1.0538 - accuracy: 0.6567\n",
            "Epoch 80/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.0822 - accuracy: 0.6400\n",
            "Epoch 81/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 1.0778 - accuracy: 0.6433\n",
            "Epoch 82/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.0783 - accuracy: 0.6317\n",
            "Epoch 83/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 1.0907 - accuracy: 0.6217\n",
            "Epoch 84/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.0999 - accuracy: 0.6133\n",
            "Epoch 85/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 1.0855 - accuracy: 0.6250\n",
            "Epoch 86/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.0477 - accuracy: 0.6283\n",
            "Epoch 87/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 1.0513 - accuracy: 0.6217\n",
            "Epoch 88/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 1.0344 - accuracy: 0.6533\n",
            "Epoch 89/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 1.0073 - accuracy: 0.6417\n",
            "Epoch 90/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.9972 - accuracy: 0.6500\n",
            "Epoch 91/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 1.0299 - accuracy: 0.6500\n",
            "Epoch 92/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 1.0172 - accuracy: 0.6500\n",
            "Epoch 93/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.9991 - accuracy: 0.6700\n",
            "Epoch 94/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.9805 - accuracy: 0.6783\n",
            "Epoch 95/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.9983 - accuracy: 0.6333\n",
            "Epoch 96/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.9776 - accuracy: 0.6617\n",
            "Epoch 97/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 1.0057 - accuracy: 0.6683\n",
            "Epoch 98/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.9970 - accuracy: 0.6683\n",
            "Epoch 99/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 1.0106 - accuracy: 0.6433\n",
            "Epoch 100/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.9700 - accuracy: 0.6717\n",
            "Epoch 101/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.9595 - accuracy: 0.6533\n",
            "Epoch 102/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.9770 - accuracy: 0.6367\n",
            "Epoch 103/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.9899 - accuracy: 0.6533\n",
            "Epoch 104/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.9433 - accuracy: 0.6883\n",
            "Epoch 105/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.9636 - accuracy: 0.6667\n",
            "Epoch 106/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.9575 - accuracy: 0.6667\n",
            "Epoch 107/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.9330 - accuracy: 0.6600\n",
            "Epoch 108/1000\n",
            "600/600 [==============================] - 0s 88us/step - loss: 0.9437 - accuracy: 0.6733\n",
            "Epoch 109/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.9214 - accuracy: 0.6783\n",
            "Epoch 110/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.9457 - accuracy: 0.6633\n",
            "Epoch 111/1000\n",
            "600/600 [==============================] - 0s 111us/step - loss: 0.9172 - accuracy: 0.6850\n",
            "Epoch 112/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.9024 - accuracy: 0.6917\n",
            "Epoch 113/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.9074 - accuracy: 0.6817\n",
            "Epoch 114/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.9147 - accuracy: 0.6783\n",
            "Epoch 115/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.9217 - accuracy: 0.6867\n",
            "Epoch 116/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.9205 - accuracy: 0.6733\n",
            "Epoch 117/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.9557 - accuracy: 0.6733\n",
            "Epoch 118/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.9160 - accuracy: 0.6700\n",
            "Epoch 119/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.8879 - accuracy: 0.7033\n",
            "Epoch 120/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.8740 - accuracy: 0.6983\n",
            "Epoch 121/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.8756 - accuracy: 0.7017\n",
            "Epoch 122/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.8582 - accuracy: 0.7133\n",
            "Epoch 123/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.8756 - accuracy: 0.6917\n",
            "Epoch 124/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.8683 - accuracy: 0.6900\n",
            "Epoch 125/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.9243 - accuracy: 0.6783\n",
            "Epoch 126/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.9391 - accuracy: 0.6633\n",
            "Epoch 127/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.9211 - accuracy: 0.6733\n",
            "Epoch 128/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.8677 - accuracy: 0.6833\n",
            "Epoch 129/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.8647 - accuracy: 0.6933\n",
            "Epoch 130/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.8595 - accuracy: 0.7083\n",
            "Epoch 131/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.8651 - accuracy: 0.7050\n",
            "Epoch 132/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.8659 - accuracy: 0.7033\n",
            "Epoch 133/1000\n",
            "600/600 [==============================] - 0s 88us/step - loss: 0.8703 - accuracy: 0.6933\n",
            "Epoch 134/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.8213 - accuracy: 0.7150\n",
            "Epoch 135/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.8207 - accuracy: 0.7033\n",
            "Epoch 136/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.8674 - accuracy: 0.7083\n",
            "Epoch 137/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.8560 - accuracy: 0.6783\n",
            "Epoch 138/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.8885 - accuracy: 0.6933\n",
            "Epoch 139/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.7978 - accuracy: 0.7117\n",
            "Epoch 140/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.8010 - accuracy: 0.7167\n",
            "Epoch 141/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.8176 - accuracy: 0.7033\n",
            "Epoch 142/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.7986 - accuracy: 0.7250\n",
            "Epoch 143/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.7782 - accuracy: 0.7450\n",
            "Epoch 144/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.7922 - accuracy: 0.7183\n",
            "Epoch 145/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.8098 - accuracy: 0.7183\n",
            "Epoch 146/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.7921 - accuracy: 0.7267\n",
            "Epoch 147/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.7789 - accuracy: 0.7333\n",
            "Epoch 148/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.7648 - accuracy: 0.7400\n",
            "Epoch 149/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.7728 - accuracy: 0.7400\n",
            "Epoch 150/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.7698 - accuracy: 0.7333\n",
            "Epoch 151/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.7426 - accuracy: 0.7400\n",
            "Epoch 152/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.7721 - accuracy: 0.7267\n",
            "Epoch 153/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.8104 - accuracy: 0.7250\n",
            "Epoch 154/1000\n",
            "600/600 [==============================] - 0s 89us/step - loss: 0.8432 - accuracy: 0.7133\n",
            "Epoch 155/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.9693 - accuracy: 0.6900\n",
            "Epoch 156/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.8854 - accuracy: 0.6983\n",
            "Epoch 157/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 1.2606 - accuracy: 0.6850\n",
            "Epoch 158/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.8421 - accuracy: 0.7017\n",
            "Epoch 159/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.7843 - accuracy: 0.7200\n",
            "Epoch 160/1000\n",
            "600/600 [==============================] - 0s 86us/step - loss: 0.7732 - accuracy: 0.7367\n",
            "Epoch 161/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.8171 - accuracy: 0.7050\n",
            "Epoch 162/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.7350 - accuracy: 0.7433\n",
            "Epoch 163/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.7399 - accuracy: 0.7517\n",
            "Epoch 164/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.7117 - accuracy: 0.7617\n",
            "Epoch 165/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.7435 - accuracy: 0.7267\n",
            "Epoch 166/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.7322 - accuracy: 0.7433\n",
            "Epoch 167/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.6952 - accuracy: 0.7683\n",
            "Epoch 168/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.7363 - accuracy: 0.7317\n",
            "Epoch 169/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.7678 - accuracy: 0.7183\n",
            "Epoch 170/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.7570 - accuracy: 0.7283\n",
            "Epoch 171/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.7968 - accuracy: 0.7317\n",
            "Epoch 172/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.8121 - accuracy: 0.7567\n",
            "Epoch 173/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.7117 - accuracy: 0.7517\n",
            "Epoch 174/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.7264 - accuracy: 0.7550\n",
            "Epoch 175/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.7051 - accuracy: 0.7600\n",
            "Epoch 176/1000\n",
            "600/600 [==============================] - 0s 106us/step - loss: 0.7005 - accuracy: 0.7533\n",
            "Epoch 177/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.7006 - accuracy: 0.7517\n",
            "Epoch 178/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.7001 - accuracy: 0.7567\n",
            "Epoch 179/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.6730 - accuracy: 0.7750\n",
            "Epoch 180/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.6848 - accuracy: 0.7533\n",
            "Epoch 181/1000\n",
            "600/600 [==============================] - 0s 90us/step - loss: 0.7207 - accuracy: 0.7583\n",
            "Epoch 182/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.6966 - accuracy: 0.7417\n",
            "Epoch 183/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.7131 - accuracy: 0.7383\n",
            "Epoch 184/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.6834 - accuracy: 0.7517\n",
            "Epoch 185/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.7485 - accuracy: 0.7500\n",
            "Epoch 186/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.7776 - accuracy: 0.7417\n",
            "Epoch 187/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.7098 - accuracy: 0.7617\n",
            "Epoch 188/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.7182 - accuracy: 0.7417\n",
            "Epoch 189/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.6489 - accuracy: 0.7850\n",
            "Epoch 190/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.6318 - accuracy: 0.7833\n",
            "Epoch 191/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.6505 - accuracy: 0.7667\n",
            "Epoch 192/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.6228 - accuracy: 0.7850\n",
            "Epoch 193/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.6205 - accuracy: 0.7750\n",
            "Epoch 194/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.6308 - accuracy: 0.7967\n",
            "Epoch 195/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.6624 - accuracy: 0.7783\n",
            "Epoch 196/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.6283 - accuracy: 0.7967\n",
            "Epoch 197/1000\n",
            "600/600 [==============================] - 0s 90us/step - loss: 0.6197 - accuracy: 0.7833\n",
            "Epoch 198/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.6653 - accuracy: 0.7700\n",
            "Epoch 199/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.6452 - accuracy: 0.7767\n",
            "Epoch 200/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.6518 - accuracy: 0.7717\n",
            "Epoch 201/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.6504 - accuracy: 0.7867\n",
            "Epoch 202/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.6153 - accuracy: 0.7950\n",
            "Epoch 203/1000\n",
            "600/600 [==============================] - 0s 86us/step - loss: 0.6033 - accuracy: 0.8000\n",
            "Epoch 204/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.5820 - accuracy: 0.8200\n",
            "Epoch 205/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.5744 - accuracy: 0.7917\n",
            "Epoch 206/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.5833 - accuracy: 0.7967\n",
            "Epoch 207/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.5880 - accuracy: 0.7817\n",
            "Epoch 208/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.5867 - accuracy: 0.8033\n",
            "Epoch 209/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.5981 - accuracy: 0.7917\n",
            "Epoch 210/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.6157 - accuracy: 0.7850\n",
            "Epoch 211/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.6127 - accuracy: 0.7950\n",
            "Epoch 212/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.9267 - accuracy: 0.7500\n",
            "Epoch 213/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.7442 - accuracy: 0.7550\n",
            "Epoch 214/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.6643 - accuracy: 0.7600\n",
            "Epoch 215/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.6189 - accuracy: 0.7733\n",
            "Epoch 216/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.6106 - accuracy: 0.7983\n",
            "Epoch 217/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.5842 - accuracy: 0.7967\n",
            "Epoch 218/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.6209 - accuracy: 0.7900\n",
            "Epoch 219/1000\n",
            "600/600 [==============================] - 0s 105us/step - loss: 0.6214 - accuracy: 0.7917\n",
            "Epoch 220/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.6021 - accuracy: 0.7767\n",
            "Epoch 221/1000\n",
            "600/600 [==============================] - 0s 111us/step - loss: 0.6067 - accuracy: 0.7800\n",
            "Epoch 222/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.6446 - accuracy: 0.7683\n",
            "Epoch 223/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.6111 - accuracy: 0.7833\n",
            "Epoch 224/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.5454 - accuracy: 0.8150\n",
            "Epoch 225/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.5460 - accuracy: 0.8117\n",
            "Epoch 226/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.5382 - accuracy: 0.8100\n",
            "Epoch 227/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.5454 - accuracy: 0.8083\n",
            "Epoch 228/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.5657 - accuracy: 0.8050\n",
            "Epoch 229/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.5438 - accuracy: 0.8067\n",
            "Epoch 230/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.6152 - accuracy: 0.7783\n",
            "Epoch 231/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.5643 - accuracy: 0.8100\n",
            "Epoch 232/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.6032 - accuracy: 0.7900\n",
            "Epoch 233/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.5847 - accuracy: 0.8033\n",
            "Epoch 234/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.5513 - accuracy: 0.8067\n",
            "Epoch 235/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.5894 - accuracy: 0.8017\n",
            "Epoch 236/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.5255 - accuracy: 0.8200\n",
            "Epoch 237/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.5203 - accuracy: 0.8083\n",
            "Epoch 238/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.5258 - accuracy: 0.7983\n",
            "Epoch 239/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.5339 - accuracy: 0.8200\n",
            "Epoch 240/1000\n",
            "600/600 [==============================] - 0s 90us/step - loss: 0.5007 - accuracy: 0.8150\n",
            "Epoch 241/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.5177 - accuracy: 0.8083\n",
            "Epoch 242/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.4981 - accuracy: 0.8300\n",
            "Epoch 243/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.4845 - accuracy: 0.8383\n",
            "Epoch 244/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.4990 - accuracy: 0.8250\n",
            "Epoch 245/1000\n",
            "600/600 [==============================] - 0s 99us/step - loss: 0.4865 - accuracy: 0.8200\n",
            "Epoch 246/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.5133 - accuracy: 0.8183\n",
            "Epoch 247/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.5583 - accuracy: 0.7983\n",
            "Epoch 248/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.6067 - accuracy: 0.7967\n",
            "Epoch 249/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.6231 - accuracy: 0.7767\n",
            "Epoch 250/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.5463 - accuracy: 0.8067\n",
            "Epoch 251/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.5688 - accuracy: 0.8000\n",
            "Epoch 252/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.5528 - accuracy: 0.8133\n",
            "Epoch 253/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.5153 - accuracy: 0.8183\n",
            "Epoch 254/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.4983 - accuracy: 0.8283\n",
            "Epoch 255/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.5953 - accuracy: 0.7850\n",
            "Epoch 256/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.5753 - accuracy: 0.8017\n",
            "Epoch 257/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.5485 - accuracy: 0.7950\n",
            "Epoch 258/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.5022 - accuracy: 0.8267\n",
            "Epoch 259/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.5334 - accuracy: 0.8133\n",
            "Epoch 260/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.4870 - accuracy: 0.8367\n",
            "Epoch 261/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.4661 - accuracy: 0.8483\n",
            "Epoch 262/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.4547 - accuracy: 0.8450\n",
            "Epoch 263/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.4946 - accuracy: 0.8183\n",
            "Epoch 264/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.4583 - accuracy: 0.8433\n",
            "Epoch 265/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.4605 - accuracy: 0.8583\n",
            "Epoch 266/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.4382 - accuracy: 0.8567\n",
            "Epoch 267/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.4387 - accuracy: 0.8467\n",
            "Epoch 268/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.4488 - accuracy: 0.8533\n",
            "Epoch 269/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.4315 - accuracy: 0.8517\n",
            "Epoch 270/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.4599 - accuracy: 0.8550\n",
            "Epoch 271/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.4259 - accuracy: 0.8467\n",
            "Epoch 272/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.4188 - accuracy: 0.8417\n",
            "Epoch 273/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.4711 - accuracy: 0.8350\n",
            "Epoch 274/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.4262 - accuracy: 0.8533\n",
            "Epoch 275/1000\n",
            "600/600 [==============================] - 0s 99us/step - loss: 0.4509 - accuracy: 0.8467\n",
            "Epoch 276/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.4319 - accuracy: 0.8517\n",
            "Epoch 277/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.4407 - accuracy: 0.8517\n",
            "Epoch 278/1000\n",
            "600/600 [==============================] - 0s 99us/step - loss: 0.4366 - accuracy: 0.8383\n",
            "Epoch 279/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.4266 - accuracy: 0.8467\n",
            "Epoch 280/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.4400 - accuracy: 0.8483\n",
            "Epoch 281/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.4236 - accuracy: 0.8450\n",
            "Epoch 282/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.5513 - accuracy: 0.8183\n",
            "Epoch 283/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.4517 - accuracy: 0.8467\n",
            "Epoch 284/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.4534 - accuracy: 0.8483\n",
            "Epoch 285/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.4187 - accuracy: 0.8600\n",
            "Epoch 286/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.4014 - accuracy: 0.8633\n",
            "Epoch 287/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.3816 - accuracy: 0.8733\n",
            "Epoch 288/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.4224 - accuracy: 0.8533\n",
            "Epoch 289/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.3998 - accuracy: 0.8617\n",
            "Epoch 290/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.4317 - accuracy: 0.8517\n",
            "Epoch 291/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.3887 - accuracy: 0.8650\n",
            "Epoch 292/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.4737 - accuracy: 0.8350\n",
            "Epoch 293/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.5039 - accuracy: 0.8450\n",
            "Epoch 294/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.4083 - accuracy: 0.8567\n",
            "Epoch 295/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.3893 - accuracy: 0.8617\n",
            "Epoch 296/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.4396 - accuracy: 0.8517\n",
            "Epoch 297/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.5370 - accuracy: 0.8333\n",
            "Epoch 298/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.4449 - accuracy: 0.8500\n",
            "Epoch 299/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.4632 - accuracy: 0.8433\n",
            "Epoch 300/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.4536 - accuracy: 0.8683\n",
            "Epoch 301/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.4461 - accuracy: 0.8500\n",
            "Epoch 302/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.4616 - accuracy: 0.8400\n",
            "Epoch 303/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.4336 - accuracy: 0.8517\n",
            "Epoch 304/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.4501 - accuracy: 0.8483\n",
            "Epoch 305/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.4084 - accuracy: 0.8700\n",
            "Epoch 306/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.4070 - accuracy: 0.8650\n",
            "Epoch 307/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.3913 - accuracy: 0.8617\n",
            "Epoch 308/1000\n",
            "600/600 [==============================] - 0s 91us/step - loss: 0.3571 - accuracy: 0.8833\n",
            "Epoch 309/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.3750 - accuracy: 0.8783\n",
            "Epoch 310/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.3623 - accuracy: 0.8717\n",
            "Epoch 311/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.3534 - accuracy: 0.8783\n",
            "Epoch 312/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.4231 - accuracy: 0.8517\n",
            "Epoch 313/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.3850 - accuracy: 0.8733\n",
            "Epoch 314/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.3836 - accuracy: 0.8717\n",
            "Epoch 315/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.4510 - accuracy: 0.8450\n",
            "Epoch 316/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.4906 - accuracy: 0.8133\n",
            "Epoch 317/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.5364 - accuracy: 0.8317\n",
            "Epoch 318/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.5012 - accuracy: 0.8283\n",
            "Epoch 319/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.5138 - accuracy: 0.8417\n",
            "Epoch 320/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.5264 - accuracy: 0.8350\n",
            "Epoch 321/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.6238 - accuracy: 0.7933\n",
            "Epoch 322/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.4531 - accuracy: 0.8467\n",
            "Epoch 323/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.3897 - accuracy: 0.8500\n",
            "Epoch 324/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.3631 - accuracy: 0.8733\n",
            "Epoch 325/1000\n",
            "600/600 [==============================] - 0s 84us/step - loss: 0.3522 - accuracy: 0.8833\n",
            "Epoch 326/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.3587 - accuracy: 0.8767\n",
            "Epoch 327/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.3699 - accuracy: 0.8683\n",
            "Epoch 328/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.3948 - accuracy: 0.8583\n",
            "Epoch 329/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.3696 - accuracy: 0.8583\n",
            "Epoch 330/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.3708 - accuracy: 0.8700\n",
            "Epoch 331/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.3938 - accuracy: 0.8633\n",
            "Epoch 332/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.4018 - accuracy: 0.8567\n",
            "Epoch 333/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.3972 - accuracy: 0.8583\n",
            "Epoch 334/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.3878 - accuracy: 0.8650\n",
            "Epoch 335/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.3459 - accuracy: 0.8867\n",
            "Epoch 336/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.3942 - accuracy: 0.8467\n",
            "Epoch 337/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.4078 - accuracy: 0.8567\n",
            "Epoch 338/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.4952 - accuracy: 0.8500\n",
            "Epoch 339/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.4067 - accuracy: 0.8683\n",
            "Epoch 340/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.3478 - accuracy: 0.8800\n",
            "Epoch 341/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.3693 - accuracy: 0.8550\n",
            "Epoch 342/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.3547 - accuracy: 0.8733\n",
            "Epoch 343/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.3512 - accuracy: 0.8833\n",
            "Epoch 344/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.3596 - accuracy: 0.8717\n",
            "Epoch 345/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.3315 - accuracy: 0.8833\n",
            "Epoch 346/1000\n",
            "600/600 [==============================] - 0s 102us/step - loss: 0.3236 - accuracy: 0.8867\n",
            "Epoch 347/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.3239 - accuracy: 0.9033\n",
            "Epoch 348/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.3660 - accuracy: 0.8700\n",
            "Epoch 349/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.3048 - accuracy: 0.9033\n",
            "Epoch 350/1000\n",
            "600/600 [==============================] - 0s 95us/step - loss: 0.3053 - accuracy: 0.9000\n",
            "Epoch 351/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.2906 - accuracy: 0.9150\n",
            "Epoch 352/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.3075 - accuracy: 0.8950\n",
            "Epoch 353/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2914 - accuracy: 0.8950\n",
            "Epoch 354/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.3655 - accuracy: 0.8783\n",
            "Epoch 355/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.3326 - accuracy: 0.8867\n",
            "Epoch 356/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.2953 - accuracy: 0.9083\n",
            "Epoch 357/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.4092 - accuracy: 0.8800\n",
            "Epoch 358/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.3995 - accuracy: 0.8617\n",
            "Epoch 359/1000\n",
            "600/600 [==============================] - 0s 84us/step - loss: 0.2901 - accuracy: 0.9000\n",
            "Epoch 360/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2792 - accuracy: 0.9067\n",
            "Epoch 361/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.3460 - accuracy: 0.8767\n",
            "Epoch 362/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.3909 - accuracy: 0.8550\n",
            "Epoch 363/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.3172 - accuracy: 0.8933\n",
            "Epoch 364/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.3252 - accuracy: 0.8950\n",
            "Epoch 365/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2831 - accuracy: 0.8983\n",
            "Epoch 366/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.3034 - accuracy: 0.8933\n",
            "Epoch 367/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.2830 - accuracy: 0.9183\n",
            "Epoch 368/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2714 - accuracy: 0.9083\n",
            "Epoch 369/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2750 - accuracy: 0.9117\n",
            "Epoch 370/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2973 - accuracy: 0.8917\n",
            "Epoch 371/1000\n",
            "600/600 [==============================] - 0s 88us/step - loss: 0.2709 - accuracy: 0.9017\n",
            "Epoch 372/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2843 - accuracy: 0.8967\n",
            "Epoch 373/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.3794 - accuracy: 0.8683\n",
            "Epoch 374/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.3184 - accuracy: 0.8850\n",
            "Epoch 375/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.3177 - accuracy: 0.9067\n",
            "Epoch 376/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.2816 - accuracy: 0.9083\n",
            "Epoch 377/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2734 - accuracy: 0.9067\n",
            "Epoch 378/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2564 - accuracy: 0.9183\n",
            "Epoch 379/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.2521 - accuracy: 0.9183\n",
            "Epoch 380/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.2696 - accuracy: 0.9267\n",
            "Epoch 381/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.2269 - accuracy: 0.9267\n",
            "Epoch 382/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.2451 - accuracy: 0.9200\n",
            "Epoch 383/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2633 - accuracy: 0.9100\n",
            "Epoch 384/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2705 - accuracy: 0.9167\n",
            "Epoch 385/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.2898 - accuracy: 0.9017\n",
            "Epoch 386/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.2588 - accuracy: 0.9117\n",
            "Epoch 387/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2467 - accuracy: 0.9233\n",
            "Epoch 388/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.3148 - accuracy: 0.8967\n",
            "Epoch 389/1000\n",
            "600/600 [==============================] - 0s 103us/step - loss: 0.3204 - accuracy: 0.8917\n",
            "Epoch 390/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.4836 - accuracy: 0.8467\n",
            "Epoch 391/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.3382 - accuracy: 0.8867\n",
            "Epoch 392/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.3245 - accuracy: 0.8917\n",
            "Epoch 393/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.2983 - accuracy: 0.9033\n",
            "Epoch 394/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.3037 - accuracy: 0.9050\n",
            "Epoch 395/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.2712 - accuracy: 0.9083\n",
            "Epoch 396/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.2639 - accuracy: 0.9033\n",
            "Epoch 397/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.2785 - accuracy: 0.9083\n",
            "Epoch 398/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.3566 - accuracy: 0.8917\n",
            "Epoch 399/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.4351 - accuracy: 0.8667\n",
            "Epoch 400/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.3852 - accuracy: 0.8750\n",
            "Epoch 401/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.2951 - accuracy: 0.9000\n",
            "Epoch 402/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.3039 - accuracy: 0.8850\n",
            "Epoch 403/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.3118 - accuracy: 0.9100\n",
            "Epoch 404/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.2761 - accuracy: 0.9100\n",
            "Epoch 405/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2303 - accuracy: 0.9200\n",
            "Epoch 406/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2129 - accuracy: 0.9333\n",
            "Epoch 407/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.2231 - accuracy: 0.9317\n",
            "Epoch 408/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.2193 - accuracy: 0.9300\n",
            "Epoch 409/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.2330 - accuracy: 0.9333\n",
            "Epoch 410/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.2260 - accuracy: 0.9267\n",
            "Epoch 411/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2338 - accuracy: 0.9167\n",
            "Epoch 412/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2264 - accuracy: 0.9267\n",
            "Epoch 413/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.2371 - accuracy: 0.9233\n",
            "Epoch 414/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.2223 - accuracy: 0.9200\n",
            "Epoch 415/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.2312 - accuracy: 0.9233\n",
            "Epoch 416/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.3033 - accuracy: 0.9050\n",
            "Epoch 417/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.3095 - accuracy: 0.8917\n",
            "Epoch 418/1000\n",
            "600/600 [==============================] - 0s 66us/step - loss: 0.2500 - accuracy: 0.9233\n",
            "Epoch 419/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2662 - accuracy: 0.9017\n",
            "Epoch 420/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.3388 - accuracy: 0.8967\n",
            "Epoch 421/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.2311 - accuracy: 0.9150\n",
            "Epoch 422/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2170 - accuracy: 0.9400\n",
            "Epoch 423/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.2283 - accuracy: 0.9200\n",
            "Epoch 424/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2502 - accuracy: 0.9117\n",
            "Epoch 425/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.2545 - accuracy: 0.9100\n",
            "Epoch 426/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2510 - accuracy: 0.9200\n",
            "Epoch 427/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2506 - accuracy: 0.9133\n",
            "Epoch 428/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.3544 - accuracy: 0.8800\n",
            "Epoch 429/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.3188 - accuracy: 0.9150\n",
            "Epoch 430/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2512 - accuracy: 0.9267\n",
            "Epoch 431/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2187 - accuracy: 0.9317\n",
            "Epoch 432/1000\n",
            "600/600 [==============================] - 0s 108us/step - loss: 0.2892 - accuracy: 0.9083\n",
            "Epoch 433/1000\n",
            "600/600 [==============================] - 0s 94us/step - loss: 0.3616 - accuracy: 0.8850\n",
            "Epoch 434/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.3746 - accuracy: 0.8800\n",
            "Epoch 435/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.3240 - accuracy: 0.8767\n",
            "Epoch 436/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.3299 - accuracy: 0.8967\n",
            "Epoch 437/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2709 - accuracy: 0.9050\n",
            "Epoch 438/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.2128 - accuracy: 0.9233\n",
            "Epoch 439/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.4528 - accuracy: 0.8800\n",
            "Epoch 440/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.3039 - accuracy: 0.8900\n",
            "Epoch 441/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.2625 - accuracy: 0.8983\n",
            "Epoch 442/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.4959 - accuracy: 0.8567\n",
            "Epoch 443/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.3766 - accuracy: 0.8717\n",
            "Epoch 444/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.3012 - accuracy: 0.9083\n",
            "Epoch 445/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2561 - accuracy: 0.9167\n",
            "Epoch 446/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2890 - accuracy: 0.9000\n",
            "Epoch 447/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.2427 - accuracy: 0.9300\n",
            "Epoch 448/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.2833 - accuracy: 0.9167\n",
            "Epoch 449/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2710 - accuracy: 0.9133\n",
            "Epoch 450/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2663 - accuracy: 0.9033\n",
            "Epoch 451/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2699 - accuracy: 0.8967\n",
            "Epoch 452/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.2629 - accuracy: 0.9083\n",
            "Epoch 453/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.2907 - accuracy: 0.8983\n",
            "Epoch 454/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2745 - accuracy: 0.9100\n",
            "Epoch 455/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.2714 - accuracy: 0.9067\n",
            "Epoch 456/1000\n",
            "600/600 [==============================] - 0s 89us/step - loss: 0.2167 - accuracy: 0.9317\n",
            "Epoch 457/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.1995 - accuracy: 0.9400\n",
            "Epoch 458/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.1785 - accuracy: 0.9483\n",
            "Epoch 459/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1719 - accuracy: 0.9450\n",
            "Epoch 460/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.1588 - accuracy: 0.9550\n",
            "Epoch 461/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1704 - accuracy: 0.9517\n",
            "Epoch 462/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2389 - accuracy: 0.9383\n",
            "Epoch 463/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.2297 - accuracy: 0.9133\n",
            "Epoch 464/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2441 - accuracy: 0.9217\n",
            "Epoch 465/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.3224 - accuracy: 0.8900\n",
            "Epoch 466/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2426 - accuracy: 0.9267\n",
            "Epoch 467/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.2852 - accuracy: 0.9283\n",
            "Epoch 468/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.2970 - accuracy: 0.9100\n",
            "Epoch 469/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.2354 - accuracy: 0.9167\n",
            "Epoch 470/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.2328 - accuracy: 0.9250\n",
            "Epoch 471/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1918 - accuracy: 0.9383\n",
            "Epoch 472/1000\n",
            "600/600 [==============================] - 0s 86us/step - loss: 0.1756 - accuracy: 0.9433\n",
            "Epoch 473/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1641 - accuracy: 0.9400\n",
            "Epoch 474/1000\n",
            "600/600 [==============================] - 0s 90us/step - loss: 0.1817 - accuracy: 0.9367\n",
            "Epoch 475/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1919 - accuracy: 0.9483\n",
            "Epoch 476/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.1907 - accuracy: 0.9417\n",
            "Epoch 477/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.1945 - accuracy: 0.9467\n",
            "Epoch 478/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1692 - accuracy: 0.9533\n",
            "Epoch 479/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1788 - accuracy: 0.9500\n",
            "Epoch 480/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1542 - accuracy: 0.9600\n",
            "Epoch 481/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1442 - accuracy: 0.9667\n",
            "Epoch 482/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1344 - accuracy: 0.9617\n",
            "Epoch 483/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.1305 - accuracy: 0.9700\n",
            "Epoch 484/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1373 - accuracy: 0.9617\n",
            "Epoch 485/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1357 - accuracy: 0.9600\n",
            "Epoch 486/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1326 - accuracy: 0.9617\n",
            "Epoch 487/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.2317 - accuracy: 0.9367\n",
            "Epoch 488/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.2777 - accuracy: 0.9100\n",
            "Epoch 489/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2299 - accuracy: 0.9317\n",
            "Epoch 490/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.2137 - accuracy: 0.9383\n",
            "Epoch 491/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.2929 - accuracy: 0.9100\n",
            "Epoch 492/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.2338 - accuracy: 0.9183\n",
            "Epoch 493/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.1662 - accuracy: 0.9483\n",
            "Epoch 494/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2352 - accuracy: 0.9350\n",
            "Epoch 495/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.2274 - accuracy: 0.9150\n",
            "Epoch 496/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.1894 - accuracy: 0.9450\n",
            "Epoch 497/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1876 - accuracy: 0.9383\n",
            "Epoch 498/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1292 - accuracy: 0.9683\n",
            "Epoch 499/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.1482 - accuracy: 0.9550\n",
            "Epoch 500/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.1615 - accuracy: 0.9467\n",
            "Epoch 501/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2034 - accuracy: 0.9350\n",
            "Epoch 502/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.2006 - accuracy: 0.9317\n",
            "Epoch 503/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.2513 - accuracy: 0.9400\n",
            "Epoch 504/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1507 - accuracy: 0.9533\n",
            "Epoch 505/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.1414 - accuracy: 0.9583\n",
            "Epoch 506/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.1362 - accuracy: 0.9650\n",
            "Epoch 507/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2004 - accuracy: 0.9367\n",
            "Epoch 508/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1799 - accuracy: 0.9533\n",
            "Epoch 509/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1424 - accuracy: 0.9617\n",
            "Epoch 510/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1723 - accuracy: 0.9500\n",
            "Epoch 511/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1773 - accuracy: 0.9500\n",
            "Epoch 512/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 1.0601 - accuracy: 0.8333\n",
            "Epoch 513/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 1.2377 - accuracy: 0.7833\n",
            "Epoch 514/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 1.4312 - accuracy: 0.7100\n",
            "Epoch 515/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.9895 - accuracy: 0.7383\n",
            "Epoch 516/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.6177 - accuracy: 0.7900\n",
            "Epoch 517/1000\n",
            "600/600 [==============================] - 0s 107us/step - loss: 0.6501 - accuracy: 0.7983\n",
            "Epoch 518/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.3747 - accuracy: 0.8633\n",
            "Epoch 519/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2850 - accuracy: 0.9117\n",
            "Epoch 520/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.2220 - accuracy: 0.9283\n",
            "Epoch 521/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.1785 - accuracy: 0.9433\n",
            "Epoch 522/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2022 - accuracy: 0.9383\n",
            "Epoch 523/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1868 - accuracy: 0.9383\n",
            "Epoch 524/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1799 - accuracy: 0.9450\n",
            "Epoch 525/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.1916 - accuracy: 0.9450\n",
            "Epoch 526/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.2020 - accuracy: 0.9483\n",
            "Epoch 527/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.1707 - accuracy: 0.9483\n",
            "Epoch 528/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1966 - accuracy: 0.9517\n",
            "Epoch 529/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.1508 - accuracy: 0.9650\n",
            "Epoch 530/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.1367 - accuracy: 0.9700\n",
            "Epoch 531/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1290 - accuracy: 0.9750\n",
            "Epoch 532/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1334 - accuracy: 0.9650\n",
            "Epoch 533/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1440 - accuracy: 0.9633\n",
            "Epoch 534/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.1213 - accuracy: 0.9750\n",
            "Epoch 535/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1391 - accuracy: 0.9667\n",
            "Epoch 536/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1409 - accuracy: 0.9617\n",
            "Epoch 537/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1195 - accuracy: 0.9783\n",
            "Epoch 538/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.1198 - accuracy: 0.9683\n",
            "Epoch 539/1000\n",
            "600/600 [==============================] - 0s 91us/step - loss: 0.1179 - accuracy: 0.9667\n",
            "Epoch 540/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1250 - accuracy: 0.9750\n",
            "Epoch 541/1000\n",
            "600/600 [==============================] - 0s 84us/step - loss: 0.1161 - accuracy: 0.9783\n",
            "Epoch 542/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.1156 - accuracy: 0.9800\n",
            "Epoch 543/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.1143 - accuracy: 0.9683\n",
            "Epoch 544/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1148 - accuracy: 0.9717\n",
            "Epoch 545/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1204 - accuracy: 0.9633\n",
            "Epoch 546/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1408 - accuracy: 0.9667\n",
            "Epoch 547/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.1455 - accuracy: 0.9517\n",
            "Epoch 548/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.1106 - accuracy: 0.9783\n",
            "Epoch 549/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1031 - accuracy: 0.9767\n",
            "Epoch 550/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1059 - accuracy: 0.9717\n",
            "Epoch 551/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1074 - accuracy: 0.9717\n",
            "Epoch 552/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.1160 - accuracy: 0.9733\n",
            "Epoch 553/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.1025 - accuracy: 0.9750\n",
            "Epoch 554/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1171 - accuracy: 0.9700\n",
            "Epoch 555/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.1232 - accuracy: 0.9683\n",
            "Epoch 556/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.2007 - accuracy: 0.9567\n",
            "Epoch 557/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.3144 - accuracy: 0.9100\n",
            "Epoch 558/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.2958 - accuracy: 0.9217\n",
            "Epoch 559/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.3632 - accuracy: 0.8783\n",
            "Epoch 560/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.1994 - accuracy: 0.9367\n",
            "Epoch 561/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2148 - accuracy: 0.9433\n",
            "Epoch 562/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1603 - accuracy: 0.9600\n",
            "Epoch 563/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.1296 - accuracy: 0.9733\n",
            "Epoch 564/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1399 - accuracy: 0.9633\n",
            "Epoch 565/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1305 - accuracy: 0.9700\n",
            "Epoch 566/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1149 - accuracy: 0.9783\n",
            "Epoch 567/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1005 - accuracy: 0.9850\n",
            "Epoch 568/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0943 - accuracy: 0.9783\n",
            "Epoch 569/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1042 - accuracy: 0.9800\n",
            "Epoch 570/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1533 - accuracy: 0.9617\n",
            "Epoch 571/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.1193 - accuracy: 0.9717\n",
            "Epoch 572/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0979 - accuracy: 0.9867\n",
            "Epoch 573/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.1201 - accuracy: 0.9667\n",
            "Epoch 574/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1533 - accuracy: 0.9583\n",
            "Epoch 575/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.1398 - accuracy: 0.9600\n",
            "Epoch 576/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.1578 - accuracy: 0.9467\n",
            "Epoch 577/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1219 - accuracy: 0.9700\n",
            "Epoch 578/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1254 - accuracy: 0.9667\n",
            "Epoch 579/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1288 - accuracy: 0.9667\n",
            "Epoch 580/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1170 - accuracy: 0.9683\n",
            "Epoch 581/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.1021 - accuracy: 0.9817\n",
            "Epoch 582/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.1096 - accuracy: 0.9817\n",
            "Epoch 583/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1061 - accuracy: 0.9767\n",
            "Epoch 584/1000\n",
            "600/600 [==============================] - 0s 84us/step - loss: 0.1057 - accuracy: 0.9750\n",
            "Epoch 585/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0928 - accuracy: 0.9783\n",
            "Epoch 586/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0843 - accuracy: 0.9867\n",
            "Epoch 587/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0950 - accuracy: 0.9767\n",
            "Epoch 588/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0843 - accuracy: 0.9833\n",
            "Epoch 589/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0752 - accuracy: 0.9867\n",
            "Epoch 590/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1149 - accuracy: 0.9717\n",
            "Epoch 591/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.1182 - accuracy: 0.9717\n",
            "Epoch 592/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1202 - accuracy: 0.9717\n",
            "Epoch 593/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.1505 - accuracy: 0.9500\n",
            "Epoch 594/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.1841 - accuracy: 0.9483\n",
            "Epoch 595/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1346 - accuracy: 0.9683\n",
            "Epoch 596/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1696 - accuracy: 0.9550\n",
            "Epoch 597/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.2058 - accuracy: 0.9383\n",
            "Epoch 598/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.1884 - accuracy: 0.9483\n",
            "Epoch 599/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2420 - accuracy: 0.9333\n",
            "Epoch 600/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1447 - accuracy: 0.9567\n",
            "Epoch 601/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1361 - accuracy: 0.9550\n",
            "Epoch 602/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1586 - accuracy: 0.9583\n",
            "Epoch 603/1000\n",
            "600/600 [==============================] - 0s 86us/step - loss: 0.1260 - accuracy: 0.9650\n",
            "Epoch 604/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1271 - accuracy: 0.9633\n",
            "Epoch 605/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.1061 - accuracy: 0.9750\n",
            "Epoch 606/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0966 - accuracy: 0.9767\n",
            "Epoch 607/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1092 - accuracy: 0.9700\n",
            "Epoch 608/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0929 - accuracy: 0.9833\n",
            "Epoch 609/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.1098 - accuracy: 0.9683\n",
            "Epoch 610/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.0999 - accuracy: 0.9750\n",
            "Epoch 611/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0812 - accuracy: 0.9833\n",
            "Epoch 612/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0800 - accuracy: 0.9833\n",
            "Epoch 613/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0895 - accuracy: 0.9800\n",
            "Epoch 614/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1205 - accuracy: 0.9700\n",
            "Epoch 615/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0798 - accuracy: 0.9850\n",
            "Epoch 616/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1017 - accuracy: 0.9750\n",
            "Epoch 617/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0805 - accuracy: 0.9917\n",
            "Epoch 618/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0672 - accuracy: 0.9800\n",
            "Epoch 619/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0688 - accuracy: 0.9917\n",
            "Epoch 620/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0694 - accuracy: 0.9867\n",
            "Epoch 621/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0662 - accuracy: 0.9850\n",
            "Epoch 622/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0681 - accuracy: 0.9900\n",
            "Epoch 623/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0763 - accuracy: 0.9850\n",
            "Epoch 624/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1444 - accuracy: 0.9650\n",
            "Epoch 625/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.2555 - accuracy: 0.9317\n",
            "Epoch 626/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1835 - accuracy: 0.9533\n",
            "Epoch 627/1000\n",
            "600/600 [==============================] - 0s 97us/step - loss: 0.1698 - accuracy: 0.9533\n",
            "Epoch 628/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.3776 - accuracy: 0.9500\n",
            "Epoch 629/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.6374 - accuracy: 0.8383\n",
            "Epoch 630/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.5503 - accuracy: 0.8583\n",
            "Epoch 631/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.4184 - accuracy: 0.8917\n",
            "Epoch 632/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.3498 - accuracy: 0.8867\n",
            "Epoch 633/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2366 - accuracy: 0.9317\n",
            "Epoch 634/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2242 - accuracy: 0.9417\n",
            "Epoch 635/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.2438 - accuracy: 0.9250\n",
            "Epoch 636/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1537 - accuracy: 0.9483\n",
            "Epoch 637/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1438 - accuracy: 0.9600\n",
            "Epoch 638/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1306 - accuracy: 0.9633\n",
            "Epoch 639/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.1219 - accuracy: 0.9733\n",
            "Epoch 640/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.0815 - accuracy: 0.9900\n",
            "Epoch 641/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0913 - accuracy: 0.9833\n",
            "Epoch 642/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0897 - accuracy: 0.9800\n",
            "Epoch 643/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0897 - accuracy: 0.9867\n",
            "Epoch 644/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0806 - accuracy: 0.9867\n",
            "Epoch 645/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1015 - accuracy: 0.9717\n",
            "Epoch 646/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0678 - accuracy: 0.9833\n",
            "Epoch 647/1000\n",
            "600/600 [==============================] - 0s 121us/step - loss: 0.0609 - accuracy: 0.9917\n",
            "Epoch 648/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.0667 - accuracy: 0.9883\n",
            "Epoch 649/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1098 - accuracy: 0.9700\n",
            "Epoch 650/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0800 - accuracy: 0.9783\n",
            "Epoch 651/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0708 - accuracy: 0.9867\n",
            "Epoch 652/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0611 - accuracy: 0.9883\n",
            "Epoch 653/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0570 - accuracy: 0.9933\n",
            "Epoch 654/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.0508 - accuracy: 0.9950\n",
            "Epoch 655/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0610 - accuracy: 0.9933\n",
            "Epoch 656/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0584 - accuracy: 0.9933\n",
            "Epoch 657/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0583 - accuracy: 0.9983\n",
            "Epoch 658/1000\n",
            "600/600 [==============================] - 0s 93us/step - loss: 0.0504 - accuracy: 0.9967\n",
            "Epoch 659/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0774 - accuracy: 0.9817\n",
            "Epoch 660/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0900 - accuracy: 0.9800\n",
            "Epoch 661/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0880 - accuracy: 0.9833\n",
            "Epoch 662/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0576 - accuracy: 0.9933\n",
            "Epoch 663/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0572 - accuracy: 0.9933\n",
            "Epoch 664/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0465 - accuracy: 0.9983\n",
            "Epoch 665/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0500 - accuracy: 0.9900\n",
            "Epoch 666/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0602 - accuracy: 0.9917\n",
            "Epoch 667/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0559 - accuracy: 0.9900\n",
            "Epoch 668/1000\n",
            "600/600 [==============================] - 0s 88us/step - loss: 0.0892 - accuracy: 0.9817\n",
            "Epoch 669/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.0575 - accuracy: 0.9867\n",
            "Epoch 670/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0575 - accuracy: 0.9917\n",
            "Epoch 671/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0623 - accuracy: 0.9883\n",
            "Epoch 672/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0821 - accuracy: 0.9833\n",
            "Epoch 673/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1449 - accuracy: 0.9500\n",
            "Epoch 674/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1689 - accuracy: 0.9500\n",
            "Epoch 675/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1515 - accuracy: 0.9633\n",
            "Epoch 676/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.0998 - accuracy: 0.9700\n",
            "Epoch 677/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1050 - accuracy: 0.9700\n",
            "Epoch 678/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0802 - accuracy: 0.9850\n",
            "Epoch 679/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0982 - accuracy: 0.9750\n",
            "Epoch 680/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1890 - accuracy: 0.9533\n",
            "Epoch 681/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1194 - accuracy: 0.9700\n",
            "Epoch 682/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.3196 - accuracy: 0.9233\n",
            "Epoch 683/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2308 - accuracy: 0.9567\n",
            "Epoch 684/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.2283 - accuracy: 0.9400\n",
            "Epoch 685/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1395 - accuracy: 0.9450\n",
            "Epoch 686/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0896 - accuracy: 0.9783\n",
            "Epoch 687/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0666 - accuracy: 0.9917\n",
            "Epoch 688/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0711 - accuracy: 0.9867\n",
            "Epoch 689/1000\n",
            "600/600 [==============================] - 0s 88us/step - loss: 0.0511 - accuracy: 0.9950\n",
            "Epoch 690/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.0498 - accuracy: 0.9950\n",
            "Epoch 691/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.0765 - accuracy: 0.9883\n",
            "Epoch 692/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0698 - accuracy: 0.9850\n",
            "Epoch 693/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0658 - accuracy: 0.9883\n",
            "Epoch 694/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0591 - accuracy: 0.9917\n",
            "Epoch 695/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0719 - accuracy: 0.9883\n",
            "Epoch 696/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0592 - accuracy: 0.9900\n",
            "Epoch 697/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0628 - accuracy: 0.9867\n",
            "Epoch 698/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0552 - accuracy: 0.9917\n",
            "Epoch 699/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0518 - accuracy: 0.9950\n",
            "Epoch 700/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0573 - accuracy: 0.9883\n",
            "Epoch 701/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0635 - accuracy: 0.9883\n",
            "Epoch 702/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0612 - accuracy: 0.9900\n",
            "Epoch 703/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0434 - accuracy: 0.9933\n",
            "Epoch 704/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.0539 - accuracy: 0.9900\n",
            "Epoch 705/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0573 - accuracy: 0.9917\n",
            "Epoch 706/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0571 - accuracy: 0.9900\n",
            "Epoch 707/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0571 - accuracy: 0.9850\n",
            "Epoch 708/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0475 - accuracy: 0.9967\n",
            "Epoch 709/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0415 - accuracy: 0.9967\n",
            "Epoch 710/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0482 - accuracy: 0.9950\n",
            "Epoch 711/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.0490 - accuracy: 0.9900\n",
            "Epoch 712/1000\n",
            "600/600 [==============================] - 0s 88us/step - loss: 0.1029 - accuracy: 0.9783\n",
            "Epoch 713/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0844 - accuracy: 0.9850\n",
            "Epoch 714/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.0752 - accuracy: 0.9850\n",
            "Epoch 715/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0701 - accuracy: 0.9883\n",
            "Epoch 716/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0396 - accuracy: 0.9933\n",
            "Epoch 717/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0389 - accuracy: 0.9933\n",
            "Epoch 718/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0611 - accuracy: 0.9850\n",
            "Epoch 719/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0613 - accuracy: 0.9883\n",
            "Epoch 720/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0489 - accuracy: 0.9900\n",
            "Epoch 721/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0418 - accuracy: 0.9933\n",
            "Epoch 722/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0334 - accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0337 - accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0317 - accuracy: 0.9983\n",
            "Epoch 725/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0356 - accuracy: 0.9967\n",
            "Epoch 726/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0451 - accuracy: 0.9950\n",
            "Epoch 727/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0403 - accuracy: 0.9950\n",
            "Epoch 728/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0433 - accuracy: 0.9950\n",
            "Epoch 729/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0541 - accuracy: 0.9917\n",
            "Epoch 730/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.0683 - accuracy: 0.9900\n",
            "Epoch 731/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.0493 - accuracy: 0.9883\n",
            "Epoch 732/1000\n",
            "600/600 [==============================] - 0s 92us/step - loss: 0.0528 - accuracy: 0.9900\n",
            "Epoch 733/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.0316 - accuracy: 0.9983\n",
            "Epoch 734/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0527 - accuracy: 0.9933\n",
            "Epoch 735/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0605 - accuracy: 0.9850\n",
            "Epoch 736/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0458 - accuracy: 0.9867\n",
            "Epoch 737/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0639 - accuracy: 0.9883\n",
            "Epoch 738/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0643 - accuracy: 0.9850\n",
            "Epoch 739/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0869 - accuracy: 0.9733\n",
            "Epoch 740/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0734 - accuracy: 0.9900\n",
            "Epoch 741/1000\n",
            "600/600 [==============================] - 0s 89us/step - loss: 0.0813 - accuracy: 0.9733\n",
            "Epoch 742/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0657 - accuracy: 0.9883\n",
            "Epoch 743/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0446 - accuracy: 0.9950\n",
            "Epoch 744/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0416 - accuracy: 0.9950\n",
            "Epoch 745/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0324 - accuracy: 0.9983\n",
            "Epoch 746/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0324 - accuracy: 0.9967\n",
            "Epoch 747/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0344 - accuracy: 0.9950\n",
            "Epoch 748/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0400 - accuracy: 0.9950\n",
            "Epoch 749/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0412 - accuracy: 0.9933\n",
            "Epoch 750/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0358 - accuracy: 0.9967\n",
            "Epoch 751/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0513 - accuracy: 0.9900\n",
            "Epoch 752/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0406 - accuracy: 0.9967\n",
            "Epoch 753/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.0589 - accuracy: 0.9883\n",
            "Epoch 754/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.0806 - accuracy: 0.9817\n",
            "Epoch 755/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0770 - accuracy: 0.9783\n",
            "Epoch 756/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0608 - accuracy: 0.9833\n",
            "Epoch 757/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0907 - accuracy: 0.9750\n",
            "Epoch 758/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1051 - accuracy: 0.9750\n",
            "Epoch 759/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.1821 - accuracy: 0.9533\n",
            "Epoch 760/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.3010 - accuracy: 0.9383\n",
            "Epoch 761/1000\n",
            "600/600 [==============================] - 0s 86us/step - loss: 0.2717 - accuracy: 0.9283\n",
            "Epoch 762/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.2508 - accuracy: 0.9433\n",
            "Epoch 763/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.1869 - accuracy: 0.9400\n",
            "Epoch 764/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.1861 - accuracy: 0.9350\n",
            "Epoch 765/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.2784 - accuracy: 0.9250\n",
            "Epoch 766/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.1759 - accuracy: 0.9500\n",
            "Epoch 767/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1781 - accuracy: 0.9467\n",
            "Epoch 768/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1419 - accuracy: 0.9517\n",
            "Epoch 769/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.2286 - accuracy: 0.9367\n",
            "Epoch 770/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.3243 - accuracy: 0.9283\n",
            "Epoch 771/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.3838 - accuracy: 0.9100\n",
            "Epoch 772/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1908 - accuracy: 0.9433\n",
            "Epoch 773/1000\n",
            "600/600 [==============================] - 0s 84us/step - loss: 0.2002 - accuracy: 0.9483\n",
            "Epoch 774/1000\n",
            "600/600 [==============================] - 0s 99us/step - loss: 0.1397 - accuracy: 0.9550\n",
            "Epoch 775/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.1008 - accuracy: 0.9683\n",
            "Epoch 776/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0639 - accuracy: 0.9900\n",
            "Epoch 777/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0635 - accuracy: 0.9867\n",
            "Epoch 778/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0481 - accuracy: 0.9950\n",
            "Epoch 779/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.0384 - accuracy: 0.9983\n",
            "Epoch 780/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0328 - accuracy: 0.9983\n",
            "Epoch 781/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0457 - accuracy: 0.9933\n",
            "Epoch 782/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.1042 - accuracy: 0.9717\n",
            "Epoch 783/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.1216 - accuracy: 0.9717\n",
            "Epoch 784/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.1050 - accuracy: 0.9733\n",
            "Epoch 785/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.1171 - accuracy: 0.9700\n",
            "Epoch 786/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.0525 - accuracy: 0.9933\n",
            "Epoch 787/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0474 - accuracy: 0.9933\n",
            "Epoch 788/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0344 - accuracy: 0.9967\n",
            "Epoch 789/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0358 - accuracy: 0.9967\n",
            "Epoch 790/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0354 - accuracy: 0.9950\n",
            "Epoch 791/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0307 - accuracy: 0.9983\n",
            "Epoch 792/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0468 - accuracy: 0.9950\n",
            "Epoch 793/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0418 - accuracy: 0.9917\n",
            "Epoch 794/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0349 - accuracy: 0.9967\n",
            "Epoch 795/1000\n",
            "600/600 [==============================] - 0s 90us/step - loss: 0.0409 - accuracy: 0.9950\n",
            "Epoch 796/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.1107 - accuracy: 0.9667\n",
            "Epoch 797/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0686 - accuracy: 0.9800\n",
            "Epoch 798/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0873 - accuracy: 0.9800\n",
            "Epoch 799/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0560 - accuracy: 0.9917\n",
            "Epoch 800/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0577 - accuracy: 0.9867\n",
            "Epoch 801/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0735 - accuracy: 0.9867\n",
            "Epoch 802/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.1341 - accuracy: 0.9750\n",
            "Epoch 803/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0641 - accuracy: 0.9883\n",
            "Epoch 804/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0379 - accuracy: 0.9950\n",
            "Epoch 805/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0350 - accuracy: 0.9950\n",
            "Epoch 806/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0294 - accuracy: 0.9967\n",
            "Epoch 808/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0286 - accuracy: 0.9967\n",
            "Epoch 809/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0543 - accuracy: 0.9883\n",
            "Epoch 810/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0304 - accuracy: 0.9983\n",
            "Epoch 811/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0313 - accuracy: 0.9933\n",
            "Epoch 813/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0275 - accuracy: 0.9967\n",
            "Epoch 814/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0680 - accuracy: 0.9883\n",
            "Epoch 815/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.0403 - accuracy: 0.9950\n",
            "Epoch 816/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0366 - accuracy: 0.9967\n",
            "Epoch 817/1000\n",
            "600/600 [==============================] - 0s 119us/step - loss: 0.0274 - accuracy: 0.9983\n",
            "Epoch 818/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0264 - accuracy: 0.9983\n",
            "Epoch 819/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0260 - accuracy: 0.9967\n",
            "Epoch 820/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.0235 - accuracy: 0.9967\n",
            "Epoch 821/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.0247 - accuracy: 0.9967\n",
            "Epoch 822/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0325 - accuracy: 0.9917\n",
            "Epoch 824/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0360 - accuracy: 0.9967\n",
            "Epoch 825/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0393 - accuracy: 0.9917\n",
            "Epoch 826/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0367 - accuracy: 0.9917\n",
            "Epoch 827/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0242 - accuracy: 0.9967\n",
            "Epoch 828/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0341 - accuracy: 0.9933\n",
            "Epoch 829/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.0555 - accuracy: 0.9867\n",
            "Epoch 830/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0415 - accuracy: 0.9917\n",
            "Epoch 831/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0317 - accuracy: 0.9933\n",
            "Epoch 832/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0314 - accuracy: 0.9950\n",
            "Epoch 833/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0349 - accuracy: 0.9933\n",
            "Epoch 834/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0593 - accuracy: 0.9867\n",
            "Epoch 835/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0462 - accuracy: 0.9900\n",
            "Epoch 836/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0337 - accuracy: 0.9933\n",
            "Epoch 837/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0249 - accuracy: 0.9983\n",
            "Epoch 838/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0312 - accuracy: 0.9950\n",
            "Epoch 839/1000\n",
            "600/600 [==============================] - 0s 109us/step - loss: 0.0293 - accuracy: 0.9950\n",
            "Epoch 840/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0308 - accuracy: 0.9967\n",
            "Epoch 841/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0215 - accuracy: 0.9983\n",
            "Epoch 843/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0222 - accuracy: 0.9983\n",
            "Epoch 844/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0462 - accuracy: 0.9917\n",
            "Epoch 845/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0541 - accuracy: 0.9833\n",
            "Epoch 846/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0794 - accuracy: 0.9800\n",
            "Epoch 847/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0891 - accuracy: 0.9733\n",
            "Epoch 848/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0509 - accuracy: 0.9900\n",
            "Epoch 849/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0423 - accuracy: 0.9900\n",
            "Epoch 850/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0301 - accuracy: 0.9933\n",
            "Epoch 851/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0481 - accuracy: 0.9883\n",
            "Epoch 852/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0555 - accuracy: 0.9833\n",
            "Epoch 853/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0789 - accuracy: 0.9817\n",
            "Epoch 854/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0478 - accuracy: 0.9867\n",
            "Epoch 855/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0814 - accuracy: 0.9783\n",
            "Epoch 856/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0607 - accuracy: 0.9867\n",
            "Epoch 857/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0254 - accuracy: 0.9967\n",
            "Epoch 858/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.0298 - accuracy: 0.9933\n",
            "Epoch 859/1000\n",
            "600/600 [==============================] - 0s 93us/step - loss: 0.0247 - accuracy: 0.9933\n",
            "Epoch 860/1000\n",
            "600/600 [==============================] - 0s 98us/step - loss: 0.0274 - accuracy: 0.9950\n",
            "Epoch 861/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0452 - accuracy: 0.9900\n",
            "Epoch 862/1000\n",
            "600/600 [==============================] - 0s 82us/step - loss: 0.0445 - accuracy: 0.9900\n",
            "Epoch 863/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0327 - accuracy: 0.9950\n",
            "Epoch 864/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0269 - accuracy: 0.9967\n",
            "Epoch 865/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.0316 - accuracy: 0.9933\n",
            "Epoch 866/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0291 - accuracy: 0.9917\n",
            "Epoch 867/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0244 - accuracy: 0.9967\n",
            "Epoch 869/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0313 - accuracy: 0.9917\n",
            "Epoch 870/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0623 - accuracy: 0.9833\n",
            "Epoch 871/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0759 - accuracy: 0.9833\n",
            "Epoch 872/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1451 - accuracy: 0.9617\n",
            "Epoch 873/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.2396 - accuracy: 0.9250\n",
            "Epoch 874/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1209 - accuracy: 0.9667\n",
            "Epoch 875/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1259 - accuracy: 0.9617\n",
            "Epoch 876/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0809 - accuracy: 0.9733\n",
            "Epoch 877/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0836 - accuracy: 0.9767\n",
            "Epoch 878/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1328 - accuracy: 0.9633\n",
            "Epoch 879/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.2696 - accuracy: 0.9283\n",
            "Epoch 880/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.3183 - accuracy: 0.9250\n",
            "Epoch 881/1000\n",
            "600/600 [==============================] - 0s 87us/step - loss: 0.2099 - accuracy: 0.9483\n",
            "Epoch 882/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1348 - accuracy: 0.9700\n",
            "Epoch 883/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.1222 - accuracy: 0.9650\n",
            "Epoch 884/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.2483 - accuracy: 0.9433\n",
            "Epoch 885/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.1102 - accuracy: 0.9700\n",
            "Epoch 886/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.1029 - accuracy: 0.9717\n",
            "Epoch 887/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.1733 - accuracy: 0.9583\n",
            "Epoch 888/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.2694 - accuracy: 0.9267\n",
            "Epoch 889/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.2017 - accuracy: 0.9483\n",
            "Epoch 890/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.1333 - accuracy: 0.9650\n",
            "Epoch 891/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0907 - accuracy: 0.9683\n",
            "Epoch 892/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.1249 - accuracy: 0.9633\n",
            "Epoch 893/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1260 - accuracy: 0.9567\n",
            "Epoch 894/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1053 - accuracy: 0.9683\n",
            "Epoch 895/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.1157 - accuracy: 0.9617\n",
            "Epoch 896/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.1497 - accuracy: 0.9567\n",
            "Epoch 897/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1263 - accuracy: 0.9667\n",
            "Epoch 898/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0944 - accuracy: 0.9750\n",
            "Epoch 899/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0548 - accuracy: 0.9883\n",
            "Epoch 900/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0935 - accuracy: 0.9767\n",
            "Epoch 901/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0921 - accuracy: 0.9700\n",
            "Epoch 902/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0973 - accuracy: 0.9750\n",
            "Epoch 903/1000\n",
            "600/600 [==============================] - 0s 90us/step - loss: 0.1042 - accuracy: 0.9783\n",
            "Epoch 904/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0421 - accuracy: 0.9933\n",
            "Epoch 905/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0636 - accuracy: 0.9850\n",
            "Epoch 906/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0411 - accuracy: 0.9917\n",
            "Epoch 907/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0550 - accuracy: 0.9867\n",
            "Epoch 908/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0406 - accuracy: 0.9883\n",
            "Epoch 909/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0538 - accuracy: 0.9883\n",
            "Epoch 910/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0306 - accuracy: 0.9950\n",
            "Epoch 911/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.0233 - accuracy: 0.9950\n",
            "Epoch 912/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "600/600 [==============================] - 0s 84us/step - loss: 0.0195 - accuracy: 0.9983\n",
            "Epoch 914/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0218 - accuracy: 0.9967\n",
            "Epoch 915/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0205 - accuracy: 0.9983\n",
            "Epoch 916/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0361 - accuracy: 0.9900\n",
            "Epoch 917/1000\n",
            "600/600 [==============================] - 0s 67us/step - loss: 0.0390 - accuracy: 0.9883\n",
            "Epoch 918/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0356 - accuracy: 0.9933\n",
            "Epoch 919/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0487 - accuracy: 0.9900\n",
            "Epoch 920/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0571 - accuracy: 0.9850\n",
            "Epoch 921/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0447 - accuracy: 0.9900\n",
            "Epoch 922/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.0449 - accuracy: 0.9883\n",
            "Epoch 923/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0427 - accuracy: 0.9933\n",
            "Epoch 924/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0261 - accuracy: 0.9917\n",
            "Epoch 925/1000\n",
            "600/600 [==============================] - 0s 104us/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 926/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0195 - accuracy: 0.9967\n",
            "Epoch 927/1000\n",
            "600/600 [==============================] - 0s 85us/step - loss: 0.0160 - accuracy: 0.9983\n",
            "Epoch 928/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0196 - accuracy: 0.9983\n",
            "Epoch 929/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0208 - accuracy: 0.9950\n",
            "Epoch 930/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0301 - accuracy: 0.9933\n",
            "Epoch 936/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0185 - accuracy: 0.9983\n",
            "Epoch 937/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0155 - accuracy: 0.9983\n",
            "Epoch 938/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0209 - accuracy: 0.9967\n",
            "Epoch 939/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0142 - accuracy: 0.9983\n",
            "Epoch 940/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0157 - accuracy: 0.9983\n",
            "Epoch 941/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.0173 - accuracy: 0.9967\n",
            "Epoch 942/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0423 - accuracy: 0.9933\n",
            "Epoch 943/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0230 - accuracy: 0.9933\n",
            "Epoch 945/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0165 - accuracy: 0.9967\n",
            "Epoch 946/1000\n",
            "600/600 [==============================] - 0s 103us/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0195 - accuracy: 0.9950\n",
            "Epoch 948/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0168 - accuracy: 0.9967\n",
            "Epoch 949/1000\n",
            "600/600 [==============================] - 0s 83us/step - loss: 0.0308 - accuracy: 0.9933\n",
            "Epoch 950/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0217 - accuracy: 0.9967\n",
            "Epoch 951/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0397 - accuracy: 0.9917\n",
            "Epoch 952/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0580 - accuracy: 0.9767\n",
            "Epoch 953/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0815 - accuracy: 0.9783\n",
            "Epoch 954/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0810 - accuracy: 0.9783\n",
            "Epoch 955/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0688 - accuracy: 0.9800\n",
            "Epoch 956/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.1335 - accuracy: 0.9700\n",
            "Epoch 957/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0861 - accuracy: 0.9767\n",
            "Epoch 958/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0923 - accuracy: 0.9817\n",
            "Epoch 959/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.1000 - accuracy: 0.9717\n",
            "Epoch 960/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0731 - accuracy: 0.9833\n",
            "Epoch 961/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0330 - accuracy: 0.9917\n",
            "Epoch 962/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0251 - accuracy: 0.9950\n",
            "Epoch 963/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0382 - accuracy: 0.9950\n",
            "Epoch 964/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0195 - accuracy: 0.9983\n",
            "Epoch 965/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0146 - accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0149 - accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "600/600 [==============================] - 0s 89us/step - loss: 0.0162 - accuracy: 0.9983\n",
            "Epoch 968/1000\n",
            "600/600 [==============================] - 0s 89us/step - loss: 0.0226 - accuracy: 0.9950\n",
            "Epoch 969/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0236 - accuracy: 0.9950\n",
            "Epoch 970/1000\n",
            "600/600 [==============================] - 0s 68us/step - loss: 0.0304 - accuracy: 0.9933\n",
            "Epoch 971/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0413 - accuracy: 0.9900\n",
            "Epoch 972/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0386 - accuracy: 0.9883\n",
            "Epoch 973/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0404 - accuracy: 0.9917\n",
            "Epoch 974/1000\n",
            "600/600 [==============================] - 0s 76us/step - loss: 0.0358 - accuracy: 0.9867\n",
            "Epoch 975/1000\n",
            "600/600 [==============================] - 0s 71us/step - loss: 0.0295 - accuracy: 0.9950\n",
            "Epoch 976/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0188 - accuracy: 0.9967\n",
            "Epoch 977/1000\n",
            "600/600 [==============================] - 0s 70us/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 978/1000\n",
            "600/600 [==============================] - 0s 69us/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "600/600 [==============================] - 0s 79us/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0286 - accuracy: 0.9950\n",
            "Epoch 981/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0153 - accuracy: 0.9983\n",
            "Epoch 982/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0285 - accuracy: 0.9950\n",
            "Epoch 983/1000\n",
            "600/600 [==============================] - 0s 72us/step - loss: 0.0313 - accuracy: 0.9933\n",
            "Epoch 984/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "600/600 [==============================] - 0s 86us/step - loss: 0.0180 - accuracy: 0.9950\n",
            "Epoch 987/1000\n",
            "600/600 [==============================] - 0s 75us/step - loss: 0.0221 - accuracy: 0.9967\n",
            "Epoch 988/1000\n",
            "600/600 [==============================] - 0s 91us/step - loss: 0.0221 - accuracy: 0.9933\n",
            "Epoch 989/1000\n",
            "600/600 [==============================] - 0s 98us/step - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0147 - accuracy: 0.9983\n",
            "Epoch 992/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0206 - accuracy: 0.9950\n",
            "Epoch 993/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0367 - accuracy: 0.9900\n",
            "Epoch 994/1000\n",
            "600/600 [==============================] - 0s 80us/step - loss: 0.0318 - accuracy: 0.9950\n",
            "Epoch 995/1000\n",
            "600/600 [==============================] - 0s 73us/step - loss: 0.0143 - accuracy: 0.9967\n",
            "Epoch 996/1000\n",
            "600/600 [==============================] - 0s 77us/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "600/600 [==============================] - 0s 74us/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "600/600 [==============================] - 0s 84us/step - loss: 0.0116 - accuracy: 0.9983\n",
            "Epoch 999/1000\n",
            "600/600 [==============================] - 0s 78us/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "600/600 [==============================] - 0s 81us/step - loss: 0.0112 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18EVkTto9AOD",
        "colab_type": "text"
      },
      "source": [
        "# Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q_eLqaq3uA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e5c184f8-72b4-4c92-c8af-287f155215b5"
      },
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe2d87a12b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lXFXuES5oFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "4bcbe42a-3df1-453b-d322-12a47f531d16"
      },
      "source": [
        "plt.plot(history.history['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe2d82e1a58>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VLzJ83k8l0v",
        "colab_type": "text"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtOZ2QPf8x5e",
        "colab_type": "text"
      },
      "source": [
        "# Error Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVMGfGw684dV",
        "colab_type": "text"
      },
      "source": [
        "# Insights"
      ]
    }
  ]
}